{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyPH0CCp5iOtCAPFP5PTqbC/",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "70ed59251f40450c8fdac259225094c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0f4a51ed56ed43f78851ed9691ab33e0",
              "IPY_MODEL_9ca9698d9aba4f22932027f0cb01503a",
              "IPY_MODEL_84550646169047118dc75f862893e7a7"
            ],
            "layout": "IPY_MODEL_e3ce28e355404dd5a33a315f1f7a3358"
          }
        },
        "0f4a51ed56ed43f78851ed9691ab33e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd63687305c045c483272f50d48175c5",
            "placeholder": "​",
            "style": "IPY_MODEL_b0b0599da4854423988e9fc775bea6e2",
            "value": "modules.json: 100%"
          }
        },
        "9ca9698d9aba4f22932027f0cb01503a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b521df1727e84d0d9e8be6a4af65529d",
            "max": 349,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ef962309c9b747e2b0545c8775fb31b2",
            "value": 349
          }
        },
        "84550646169047118dc75f862893e7a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6360a94b5c974374ba93eae4e6b52606",
            "placeholder": "​",
            "style": "IPY_MODEL_aa0f998e25d04dba80a875c604e96813",
            "value": " 349/349 [00:00&lt;00:00, 16.4kB/s]"
          }
        },
        "e3ce28e355404dd5a33a315f1f7a3358": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd63687305c045c483272f50d48175c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b0b0599da4854423988e9fc775bea6e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b521df1727e84d0d9e8be6a4af65529d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ef962309c9b747e2b0545c8775fb31b2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6360a94b5c974374ba93eae4e6b52606": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa0f998e25d04dba80a875c604e96813": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2f2abc9408f54e08adf5628a36abfe2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ce249683b90848298afc7da6ac43c152",
              "IPY_MODEL_0683370b8cbe48bdb12438e694e021cf",
              "IPY_MODEL_26d257aee8574ddda6d39373f6cc3832"
            ],
            "layout": "IPY_MODEL_b4456eee17c94b529bbc634bb43930b4"
          }
        },
        "ce249683b90848298afc7da6ac43c152": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bff5f01ce84a49589f19954299316fbc",
            "placeholder": "​",
            "style": "IPY_MODEL_015835dc41b3459f85a8c013a53a88f3",
            "value": "config_sentence_transformers.json: 100%"
          }
        },
        "0683370b8cbe48bdb12438e694e021cf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_778cd735a3b3422aa726925002484870",
            "max": 124,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_67526651547649a6bce2cb0632f177e2",
            "value": 124
          }
        },
        "26d257aee8574ddda6d39373f6cc3832": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_5be4c6d9c1564308af28f0282ff3d76b",
            "placeholder": "​",
            "style": "IPY_MODEL_11e2b9c77eac461c8799e49ce7a53a61",
            "value": " 124/124 [00:00&lt;00:00, 9.43kB/s]"
          }
        },
        "b4456eee17c94b529bbc634bb43930b4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bff5f01ce84a49589f19954299316fbc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "015835dc41b3459f85a8c013a53a88f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "778cd735a3b3422aa726925002484870": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "67526651547649a6bce2cb0632f177e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5be4c6d9c1564308af28f0282ff3d76b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "11e2b9c77eac461c8799e49ce7a53a61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3a0193559e64808903edc054b150800": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_113081f962e74c5fbbaf8d091e354815",
              "IPY_MODEL_7bfe1ace21204f8d93daa6107563475c",
              "IPY_MODEL_76308253bf0f4d19bef0c894cb55c044"
            ],
            "layout": "IPY_MODEL_086815636df546749d35982405359abb"
          }
        },
        "113081f962e74c5fbbaf8d091e354815": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_25e6462a95ee4842827ea33cfaa32751",
            "placeholder": "​",
            "style": "IPY_MODEL_fb9ba6e345674f1180f204104cddaf1e",
            "value": "README.md: 100%"
          }
        },
        "7bfe1ace21204f8d93daa6107563475c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e915b1776a75437fa7f7c8e644ebd202",
            "max": 94783,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_08ce966277594710b3d1b0c5236ea919",
            "value": 94783
          }
        },
        "76308253bf0f4d19bef0c894cb55c044": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a58e65ae402e404093b0821102f18a37",
            "placeholder": "​",
            "style": "IPY_MODEL_f1c4bdf558174123b8c65d58220772ee",
            "value": " 94.8k/94.8k [00:00&lt;00:00, 1.19MB/s]"
          }
        },
        "086815636df546749d35982405359abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "25e6462a95ee4842827ea33cfaa32751": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb9ba6e345674f1180f204104cddaf1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "e915b1776a75437fa7f7c8e644ebd202": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "08ce966277594710b3d1b0c5236ea919": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "a58e65ae402e404093b0821102f18a37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f1c4bdf558174123b8c65d58220772ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1f5e9ade7d4f40cd84804229616913cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_44c97860e8f44277bd69995ce4394e37",
              "IPY_MODEL_d86016dfccf9480b844f4fae63436b99",
              "IPY_MODEL_56e8a4f12593482d9efbd410b518ee7a"
            ],
            "layout": "IPY_MODEL_2520f84e2691491ebde166683fcbf849"
          }
        },
        "44c97860e8f44277bd69995ce4394e37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6e05e6b11bfd467c9387beae583aa12e",
            "placeholder": "​",
            "style": "IPY_MODEL_ffabed7d93fb42108faf3435fb7baa46",
            "value": "sentence_bert_config.json: 100%"
          }
        },
        "d86016dfccf9480b844f4fae63436b99": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8b37b3ecb9f64c22b796a949a49a8975",
            "max": 52,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_313cdb30948c45bba0e63f365f431058",
            "value": 52
          }
        },
        "56e8a4f12593482d9efbd410b518ee7a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_56d504c56fc44e2cb9987a453619725e",
            "placeholder": "​",
            "style": "IPY_MODEL_030a70fdb0184975a7a542fb2271d245",
            "value": " 52.0/52.0 [00:00&lt;00:00, 3.75kB/s]"
          }
        },
        "2520f84e2691491ebde166683fcbf849": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e05e6b11bfd467c9387beae583aa12e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffabed7d93fb42108faf3435fb7baa46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8b37b3ecb9f64c22b796a949a49a8975": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "313cdb30948c45bba0e63f365f431058": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "56d504c56fc44e2cb9987a453619725e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "030a70fdb0184975a7a542fb2271d245": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d48bd33dfc2f4ed28da8818edb383e6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_5039a66274e94b778f840989bb47df05",
              "IPY_MODEL_8a87283142584881a8973fa7dd4fa2e8",
              "IPY_MODEL_03cefcaeb962431f9b5c34870bef3200"
            ],
            "layout": "IPY_MODEL_ac337c40e68a469aa028c91a79a0eee4"
          }
        },
        "5039a66274e94b778f840989bb47df05": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0224a45c4a1434cab38e5d7bd39b65c",
            "placeholder": "​",
            "style": "IPY_MODEL_a9e7c3282540425cac90a14b9648f2db",
            "value": "config.json: 100%"
          }
        },
        "8a87283142584881a8973fa7dd4fa2e8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f20c19253f39442bbe255bcd5422257f",
            "max": 743,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83e1b0e86e334a698e5b375507c666e3",
            "value": 743
          }
        },
        "03cefcaeb962431f9b5c34870bef3200": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_26bfbc47e3e04f22934d8454a5c98701",
            "placeholder": "​",
            "style": "IPY_MODEL_5a83e272f2cf4d16939fcb474c868779",
            "value": " 743/743 [00:00&lt;00:00, 50.6kB/s]"
          }
        },
        "ac337c40e68a469aa028c91a79a0eee4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0224a45c4a1434cab38e5d7bd39b65c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a9e7c3282540425cac90a14b9648f2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f20c19253f39442bbe255bcd5422257f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "83e1b0e86e334a698e5b375507c666e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "26bfbc47e3e04f22934d8454a5c98701": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5a83e272f2cf4d16939fcb474c868779": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2b78a8837b8447c79ddca56dd5619050": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ab17f41b6a945ed91d1650d81b1859c",
              "IPY_MODEL_b71b707c9d0b41bc9619f7111a7d522e",
              "IPY_MODEL_3094b94e1b83487a815c503199416be8"
            ],
            "layout": "IPY_MODEL_121ab6c986854b34b6c3e1198b38d13c"
          }
        },
        "3ab17f41b6a945ed91d1650d81b1859c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c99a24795e774a30a8f79a2101ef220d",
            "placeholder": "​",
            "style": "IPY_MODEL_400e0ffe532c445b83d1d95fddcea6d1",
            "value": "model.safetensors: 100%"
          }
        },
        "b71b707c9d0b41bc9619f7111a7d522e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_02fcc2fcfb3d487591ff4ffc8d0dd82b",
            "max": 133466304,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6783ccba257843a19573811848a380d7",
            "value": 133466304
          }
        },
        "3094b94e1b83487a815c503199416be8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7d2a18229f714e9fa0ba135b7a68f3dc",
            "placeholder": "​",
            "style": "IPY_MODEL_14831c74b8bc4b39bacb344dd1f8b51c",
            "value": " 133M/133M [00:03&lt;00:00, 75.0MB/s]"
          }
        },
        "121ab6c986854b34b6c3e1198b38d13c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c99a24795e774a30a8f79a2101ef220d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "400e0ffe532c445b83d1d95fddcea6d1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "02fcc2fcfb3d487591ff4ffc8d0dd82b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6783ccba257843a19573811848a380d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "7d2a18229f714e9fa0ba135b7a68f3dc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "14831c74b8bc4b39bacb344dd1f8b51c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "1c781536a78d479686d61f80b341cc2a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0a139d69596341e38e11e5a7fdb5db17",
              "IPY_MODEL_c570beb1752f43bb83a651b359f71a5c",
              "IPY_MODEL_f73c153ad29e428aa61b40d7662cafba"
            ],
            "layout": "IPY_MODEL_de79df871b8745768185387cf3f13896"
          }
        },
        "0a139d69596341e38e11e5a7fdb5db17": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bb809597c5c14ff998f987b737db9f79",
            "placeholder": "​",
            "style": "IPY_MODEL_c135775c47ca402f9ad05008f8a4bbda",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "c570beb1752f43bb83a651b359f71a5c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ccb2bcc2872a43cdabbb7869e0328359",
            "max": 366,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6c1edbac1f054a00a9ad36d1e73fb83a",
            "value": 366
          }
        },
        "f73c153ad29e428aa61b40d7662cafba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73b9a67a889a447382725db79099615a",
            "placeholder": "​",
            "style": "IPY_MODEL_aa2b0cb80e034287ae9aedc223b669d3",
            "value": " 366/366 [00:00&lt;00:00, 26.1kB/s]"
          }
        },
        "de79df871b8745768185387cf3f13896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bb809597c5c14ff998f987b737db9f79": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c135775c47ca402f9ad05008f8a4bbda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ccb2bcc2872a43cdabbb7869e0328359": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6c1edbac1f054a00a9ad36d1e73fb83a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "73b9a67a889a447382725db79099615a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "aa2b0cb80e034287ae9aedc223b669d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "85ce3c17bd844ca8922eed225a6681f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_bbecdbcdbb58406daf6a95a7a1beb178",
              "IPY_MODEL_bde8eafd3e2744198a101ddb6fa879b8",
              "IPY_MODEL_f6e80f92c07346c593c9357d891cb8f0"
            ],
            "layout": "IPY_MODEL_30ecdc9218da47c290c1594aa30328f4"
          }
        },
        "bbecdbcdbb58406daf6a95a7a1beb178": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ec278b355af846f8bca71af3b36201c9",
            "placeholder": "​",
            "style": "IPY_MODEL_76480e8771e7479885d08daba938c1da",
            "value": "vocab.txt: 100%"
          }
        },
        "bde8eafd3e2744198a101ddb6fa879b8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3dc8f300241f4a9e9b3b9aff6bbf7acc",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ff83e3e9a80d4109a2a4957045b194ab",
            "value": 231508
          }
        },
        "f6e80f92c07346c593c9357d891cb8f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_698f0ce7aff447bc9d75514811ca1098",
            "placeholder": "​",
            "style": "IPY_MODEL_75e5b916abe94991b2c4f3bce506ee7b",
            "value": " 232k/232k [00:00&lt;00:00, 1.43MB/s]"
          }
        },
        "30ecdc9218da47c290c1594aa30328f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ec278b355af846f8bca71af3b36201c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "76480e8771e7479885d08daba938c1da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3dc8f300241f4a9e9b3b9aff6bbf7acc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ff83e3e9a80d4109a2a4957045b194ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "698f0ce7aff447bc9d75514811ca1098": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "75e5b916abe94991b2c4f3bce506ee7b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d242aef2ac004dfcb491c6f272a3ad3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f52e8181ec64dbca0da1635d3fc4b07",
              "IPY_MODEL_48488cc8ccc04b3ea68b67ddf8b7572d",
              "IPY_MODEL_006cf4455f9c4a73a2abed0688a63702"
            ],
            "layout": "IPY_MODEL_d2141720879a47fd82308045f7d95b80"
          }
        },
        "4f52e8181ec64dbca0da1635d3fc4b07": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_e0c8cc89795447f4b9edd90b9f8b57c5",
            "placeholder": "​",
            "style": "IPY_MODEL_4b471306f0134844ade303ce6c7b1c90",
            "value": "tokenizer.json: 100%"
          }
        },
        "48488cc8ccc04b3ea68b67ddf8b7572d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_229aa7a77c2f4e2a8abcbdfcf4ea5020",
            "max": 711396,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_e05a925a111840d39b56b790aba2d8f5",
            "value": 711396
          }
        },
        "006cf4455f9c4a73a2abed0688a63702": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ffd36f54bc64ddeb85558f411b3fc3a",
            "placeholder": "​",
            "style": "IPY_MODEL_f29e210e86234bc69345fa2f94338136",
            "value": " 711k/711k [00:00&lt;00:00, 2.20MB/s]"
          }
        },
        "d2141720879a47fd82308045f7d95b80": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e0c8cc89795447f4b9edd90b9f8b57c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4b471306f0134844ade303ce6c7b1c90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "229aa7a77c2f4e2a8abcbdfcf4ea5020": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e05a925a111840d39b56b790aba2d8f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0ffd36f54bc64ddeb85558f411b3fc3a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f29e210e86234bc69345fa2f94338136": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "d4fe68492b6440cba779cf7ddde84102": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cb2fa31c3cf14251a09efb8ea2ae3b37",
              "IPY_MODEL_77b2833e705847a0ae96782f0e41d16a",
              "IPY_MODEL_eb8aa0f13ab74a4cbca4780e59770c96"
            ],
            "layout": "IPY_MODEL_c240bca21fdd45309d6af3dd49662df3"
          }
        },
        "cb2fa31c3cf14251a09efb8ea2ae3b37": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fe4962f6b778419aa4fe39dbb364128f",
            "placeholder": "​",
            "style": "IPY_MODEL_23cd41018a1a4a4ba477a74b68b2a36f",
            "value": "special_tokens_map.json: 100%"
          }
        },
        "77b2833e705847a0ae96782f0e41d16a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88010f7986dc40a0a0d3a33317e7fa91",
            "max": 125,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_a6362a9212bf48c19fc9dfaa1667f412",
            "value": 125
          }
        },
        "eb8aa0f13ab74a4cbca4780e59770c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4ab41264906f4514a105383b56767b22",
            "placeholder": "​",
            "style": "IPY_MODEL_b71b23dad841400cbe6e4be819344fbc",
            "value": " 125/125 [00:00&lt;00:00, 5.05kB/s]"
          }
        },
        "c240bca21fdd45309d6af3dd49662df3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fe4962f6b778419aa4fe39dbb364128f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "23cd41018a1a4a4ba477a74b68b2a36f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88010f7986dc40a0a0d3a33317e7fa91": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6362a9212bf48c19fc9dfaa1667f412": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4ab41264906f4514a105383b56767b22": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b71b23dad841400cbe6e4be819344fbc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "c3f32f068a1d4084a7a1e3fb02af38d5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_736d37004dea49ec9d58219636b9e023",
              "IPY_MODEL_dc5092482fed4f7a8957ec2210c0cf04",
              "IPY_MODEL_d809bb0523bf4bafb6f33ee99e241abe"
            ],
            "layout": "IPY_MODEL_cae58960bddf41588666b69956bd3895"
          }
        },
        "736d37004dea49ec9d58219636b9e023": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d5f750871f994987bea5c2a59379dd37",
            "placeholder": "​",
            "style": "IPY_MODEL_f05c8461cc094e33851ce904368f5827",
            "value": "1_Pooling/config.json: 100%"
          }
        },
        "dc5092482fed4f7a8957ec2210c0cf04": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a9c9d167a6eb4008ac1f8c35d0c79f66",
            "max": 190,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_80f938e95c354756a3f025c7f6f257fd",
            "value": 190
          }
        },
        "d809bb0523bf4bafb6f33ee99e241abe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2ee12b52b484492194ed1a69244b8c77",
            "placeholder": "​",
            "style": "IPY_MODEL_81fb554c888141ada1bf938e5723c8a6",
            "value": " 190/190 [00:00&lt;00:00, 10.5kB/s]"
          }
        },
        "cae58960bddf41588666b69956bd3895": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d5f750871f994987bea5c2a59379dd37": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f05c8461cc094e33851ce904368f5827": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a9c9d167a6eb4008ac1f8c35d0c79f66": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "80f938e95c354756a3f025c7f6f257fd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "2ee12b52b484492194ed1a69244b8c77": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "81fb554c888141ada1bf938e5723c8a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/winterForestStump/llm/blob/main/RAG_evaluation_LlamaIndex.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation RAG on Business section (item 1) of the 10-K SEC filing\n",
        "\n",
        "This notebook is inspired by the [article](https://cookbook.openai.com/examples/evaluation/evaluate_rag_with_llamaindex) and replicates it with using open source [Llama-3](https://huggingface.co/bartowski/Llama3-DocChat-1.0-8B-GGUF/blob/main/Llama3-DocChat-1.0-8B-Q6_K.gguf) model."
      ],
      "metadata": {
        "id": "xioJQsDwVzLE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZAfzW94Pjreg",
        "outputId": "fd83f309-2952-4a45-d095-72b6369bdc0f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting llama-cpp-python==0.2.77\n",
            "  Downloading llama_cpp_python-0.2.77.tar.gz (50.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.2/50.2 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.77) (4.12.2)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.77) (1.26.4)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python==0.2.77)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python==0.2.77) (3.1.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2>=2.11.3->llama-cpp-python==0.2.77) (2.1.5)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.2.77-cp310-cp310-linux_x86_64.whl size=132170712 sha256=077cb162cb2e1b082430cff3e068df721885db0f94409d9faca00e6076c803ba\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/55/a1/6d6c2ef6fed3ef054b4170d8bcd05a09e6dc971db7fad955ff\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.2.77\n"
          ]
        }
      ],
      "source": [
        "# Install LlamaCpp to run the model locally.\n",
        "# Enable CUDA for faster performance\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python==0.2.77"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Installimg Llama-Index libraries"
      ],
      "metadata": {
        "id": "QgwNRjxAHw7d"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture --no-stderr\n",
        "!pip install llama-index llama-index-llms-llama-cpp llama-index-embeddings-huggingface --quiet"
      ],
      "metadata": {
        "id": "1cy23b6z2rtg"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "from llama_index.llms.llama_cpp import LlamaCPP\n",
        "#from llama_index.llms.llama_cpp.llama_utils import (messages_to_prompt, completion_to_prompt)\n",
        "\n",
        "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
        "from llama_index.core.node_parser import SentenceSplitter\n",
        "from llama_index.core import Settings\n",
        "from llama_index.core import VectorStoreIndex,SimpleDirectoryReader #,ServiceContext,PromptTemplate, set_global_service_context\n",
        "from llama_index.core.response.pprint_utils import pprint_response\n",
        "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
        "from llama_index.core.query_engine import SubQuestionQueryEngine\n",
        "\n",
        "from llama_index.core.evaluation import generate_question_context_pairs\n",
        "from llama_index.core.node_parser import SimpleNodeParser\n",
        "from llama_index.core.evaluation import RetrieverEvaluator\n",
        "\n",
        "from llama_index.core.evaluation import FaithfulnessEvaluator\n",
        "from llama_index.core.evaluation import RelevancyEvaluator\n",
        "from llama_index.core.evaluation import EvaluationResult\n",
        "\n",
        "import os\n",
        "import pandas as pd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r8fJJBh336ui",
        "outputId": "f6e9c362-e7dd-4c34-a194-bf3b08c26eba"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_url\" in LlamaCPP has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_path\" in LlamaCPP has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/pydantic/_internal/_fields.py:132: UserWarning: Field \"model_kwargs\" in LlamaCPP has conflict with protected namespace \"model_\".\n",
            "\n",
            "You may be able to resolve this warning by setting `model_config['protected_namespaces'] = ()`.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Item1. Business of the 10-K CocaCola annual 1993 filing\n",
        "\n",
        "!mkdir -p 'data/coca_cola/'\n",
        "!curl 'https://raw.githubusercontent.com/winterForestStump/llm/refs/heads/main/1993_CocaCola_item1.txt' -o 'data/coca_cola/coca_cola.txt'"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRSGtyqa2zxQ",
        "outputId": "0b6fa238-3c6a-4ab2-8b20-44cbaff63dac"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 38998  100 38998    0     0   145k      0 --:--:-- --:--:-- --:--:--  145k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download the Llama-3 model\n",
        "!huggingface-cli download bartowski/Llama3-DocChat-1.0-8B-GGUF Llama3-DocChat-1.0-8B-Q6_K.gguf --local-dir ./models --local-dir-use-symlinks False"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OXpxNcOg7EfZ",
        "outputId": "2e1bd500-4fdf-4703-ce8d-f0a8616c9a91"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/commands/download.py:132: FutureWarning: Ignoring --local-dir-use-symlinks. Downloading to a local directory does not use symlinks anymore.\n",
            "  warnings.warn(\n",
            "Downloading 'Llama3-DocChat-1.0-8B-Q6_K.gguf' to 'models/.cache/huggingface/download/Llama3-DocChat-1.0-8B-Q6_K.gguf.70376adad72d1d777b2cb61c98092db796a7923de018073fcb0a1ff25b21d6d3.incomplete'\n",
            "Llama3-DocChat-1.0-8B-Q6_K.gguf: 100% 6.60G/6.60G [00:47<00:00, 138MB/s] \n",
            "Download complete. Moving file to models/Llama3-DocChat-1.0-8B-Q6_K.gguf\n",
            "models/Llama3-DocChat-1.0-8B-Q6_K.gguf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define LLM\n",
        "\n",
        "TEMP = 0\n",
        "N_CTX = 4096\n",
        "N_GPU_L = -1\n",
        "\n",
        "llm_llama = LlamaCPP(\n",
        "    model_path=\"/content/models/Llama3-DocChat-1.0-8B-Q6_K.gguf\",\n",
        "    temperature=TEMP,\n",
        "    context_window=N_CTX,\n",
        "    model_kwargs={\"n_gpu_layers\": N_GPU_L},\n",
        "    verbose=True\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22zyV2ta7Ghw",
        "outputId": "006ed394-8c1c-4881-fdb8-5ad622b04af5"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_model_loader: loaded meta data with 32 key-value pairs and 291 tensors from /content/models/Llama3-DocChat-1.0-8B-Q6_K.gguf (version GGUF V3 (latest))\n",
            "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
            "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
            "llama_model_loader: - kv   1:                               general.type str              = model\n",
            "llama_model_loader: - kv   2:                               general.name str              = Llama3 DocChat 1.0 8B\n",
            "llama_model_loader: - kv   3:                           general.basename str              = Llama3-DocChat-1.0\n",
            "llama_model_loader: - kv   4:                         general.size_label str              = 8B\n",
            "llama_model_loader: - kv   5:                            general.license str              = other\n",
            "llama_model_loader: - kv   6:                               general.tags arr[str,6]       = [\"cerebras\", \"doc-chat\", \"DocChat\", \"...\n",
            "llama_model_loader: - kv   7:                          general.languages arr[str,1]       = [\"en\"]\n",
            "llama_model_loader: - kv   8:                          llama.block_count u32              = 32\n",
            "llama_model_loader: - kv   9:                       llama.context_length u32              = 8192\n",
            "llama_model_loader: - kv  10:                     llama.embedding_length u32              = 4096\n",
            "llama_model_loader: - kv  11:                  llama.feed_forward_length u32              = 14336\n",
            "llama_model_loader: - kv  12:                 llama.attention.head_count u32              = 32\n",
            "llama_model_loader: - kv  13:              llama.attention.head_count_kv u32              = 8\n",
            "llama_model_loader: - kv  14:                       llama.rope.freq_base f32              = 500000.000000\n",
            "llama_model_loader: - kv  15:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
            "llama_model_loader: - kv  16:                          general.file_type u32              = 18\n",
            "llama_model_loader: - kv  17:                           llama.vocab_size u32              = 128256\n",
            "llama_model_loader: - kv  18:                 llama.rope.dimension_count u32              = 128\n",
            "llama_model_loader: - kv  19:                       tokenizer.ggml.model str              = gpt2\n",
            "llama_model_loader: - kv  20:                         tokenizer.ggml.pre str              = llama-bpe\n",
            "llama_model_loader: - kv  21:                      tokenizer.ggml.tokens arr[str,128256]  = [\"!\", \"\\\"\", \"#\", \"$\", \"%\", \"&\", \"'\", ...\n",
            "llama_model_loader: - kv  22:                  tokenizer.ggml.token_type arr[i32,128256]  = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, ...\n",
            "llama_model_loader: - kv  23:                      tokenizer.ggml.merges arr[str,280147]  = [\"Ġ Ġ\", \"Ġ ĠĠĠ\", \"ĠĠ ĠĠ\", \"...\n",
            "llama_model_loader: - kv  24:                tokenizer.ggml.bos_token_id u32              = 128000\n",
            "llama_model_loader: - kv  25:                tokenizer.ggml.eos_token_id u32              = 128009\n",
            "llama_model_loader: - kv  26:                    tokenizer.chat_template str              = {% set loop_messages = messages %}{% ...\n",
            "llama_model_loader: - kv  27:               general.quantization_version u32              = 2\n",
            "llama_model_loader: - kv  28:                      quantize.imatrix.file str              = /models_out/Llama3-DocChat-1.0-8B-GGU...\n",
            "llama_model_loader: - kv  29:                   quantize.imatrix.dataset str              = /training_dir/calibration_datav3.txt\n",
            "llama_model_loader: - kv  30:             quantize.imatrix.entries_count i32              = 224\n",
            "llama_model_loader: - kv  31:              quantize.imatrix.chunks_count i32              = 125\n",
            "llama_model_loader: - type  f32:   65 tensors\n",
            "llama_model_loader: - type q6_K:  226 tensors\n",
            "llm_load_vocab: special tokens cache size = 256\n",
            "llm_load_vocab: token to piece cache size = 0.8000 MB\n",
            "llm_load_print_meta: format           = GGUF V3 (latest)\n",
            "llm_load_print_meta: arch             = llama\n",
            "llm_load_print_meta: vocab type       = BPE\n",
            "llm_load_print_meta: n_vocab          = 128256\n",
            "llm_load_print_meta: n_merges         = 280147\n",
            "llm_load_print_meta: n_ctx_train      = 8192\n",
            "llm_load_print_meta: n_embd           = 4096\n",
            "llm_load_print_meta: n_head           = 32\n",
            "llm_load_print_meta: n_head_kv        = 8\n",
            "llm_load_print_meta: n_layer          = 32\n",
            "llm_load_print_meta: n_rot            = 128\n",
            "llm_load_print_meta: n_embd_head_k    = 128\n",
            "llm_load_print_meta: n_embd_head_v    = 128\n",
            "llm_load_print_meta: n_gqa            = 4\n",
            "llm_load_print_meta: n_embd_k_gqa     = 1024\n",
            "llm_load_print_meta: n_embd_v_gqa     = 1024\n",
            "llm_load_print_meta: f_norm_eps       = 0.0e+00\n",
            "llm_load_print_meta: f_norm_rms_eps   = 1.0e-05\n",
            "llm_load_print_meta: f_clamp_kqv      = 0.0e+00\n",
            "llm_load_print_meta: f_max_alibi_bias = 0.0e+00\n",
            "llm_load_print_meta: f_logit_scale    = 0.0e+00\n",
            "llm_load_print_meta: n_ff             = 14336\n",
            "llm_load_print_meta: n_expert         = 0\n",
            "llm_load_print_meta: n_expert_used    = 0\n",
            "llm_load_print_meta: causal attn      = 1\n",
            "llm_load_print_meta: pooling type     = 0\n",
            "llm_load_print_meta: rope type        = 0\n",
            "llm_load_print_meta: rope scaling     = linear\n",
            "llm_load_print_meta: freq_base_train  = 500000.0\n",
            "llm_load_print_meta: freq_scale_train = 1\n",
            "llm_load_print_meta: n_yarn_orig_ctx  = 8192\n",
            "llm_load_print_meta: rope_finetuned   = unknown\n",
            "llm_load_print_meta: ssm_d_conv       = 0\n",
            "llm_load_print_meta: ssm_d_inner      = 0\n",
            "llm_load_print_meta: ssm_d_state      = 0\n",
            "llm_load_print_meta: ssm_dt_rank      = 0\n",
            "llm_load_print_meta: model type       = 8B\n",
            "llm_load_print_meta: model ftype      = Q6_K\n",
            "llm_load_print_meta: model params     = 8.03 B\n",
            "llm_load_print_meta: model size       = 6.14 GiB (6.56 BPW) \n",
            "llm_load_print_meta: general.name     = Llama3 DocChat 1.0 8B\n",
            "llm_load_print_meta: BOS token        = 128000 '<|begin_of_text|>'\n",
            "llm_load_print_meta: EOS token        = 128009 '<|eot_id|>'\n",
            "llm_load_print_meta: LF token         = 128 'Ä'\n",
            "llm_load_print_meta: EOT token        = 128009 '<|eot_id|>'\n",
            "ggml_cuda_init: GGML_CUDA_FORCE_MMQ:   no\n",
            "ggml_cuda_init: CUDA_USE_TENSOR_CORES: yes\n",
            "ggml_cuda_init: found 1 CUDA devices:\n",
            "  Device 0: Tesla T4, compute capability 7.5, VMM: yes\n",
            "llm_load_tensors: ggml ctx size =    0.30 MiB\n",
            "llm_load_tensors: offloading 32 repeating layers to GPU\n",
            "llm_load_tensors: offloading non-repeating layers to GPU\n",
            "llm_load_tensors: offloaded 33/33 layers to GPU\n",
            "llm_load_tensors:        CPU buffer size =   410.98 MiB\n",
            "llm_load_tensors:      CUDA0 buffer size =  5871.99 MiB\n",
            ".........................................................................................\n",
            "llama_new_context_with_model: n_ctx      = 4096\n",
            "llama_new_context_with_model: n_batch    = 512\n",
            "llama_new_context_with_model: n_ubatch   = 512\n",
            "llama_new_context_with_model: flash_attn = 0\n",
            "llama_new_context_with_model: freq_base  = 500000.0\n",
            "llama_new_context_with_model: freq_scale = 1\n",
            "llama_kv_cache_init:      CUDA0 KV buffer size =   512.00 MiB\n",
            "llama_new_context_with_model: KV self size  =  512.00 MiB, K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host  output buffer size =     0.49 MiB\n",
            "llama_new_context_with_model:      CUDA0 compute buffer size =   296.00 MiB\n",
            "llama_new_context_with_model:  CUDA_Host compute buffer size =    16.01 MiB\n",
            "llama_new_context_with_model: graph nodes  = 1030\n",
            "llama_new_context_with_model: graph splits = 2\n",
            "AVX = 1 | AVX_VNNI = 0 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | AVX512_BF16 = 0 | FMA = 1 | NEON = 0 | SVE = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | MATMUL_INT8 = 0 | LLAMAFILE = 1 | \n",
            "Model metadata: {'quantize.imatrix.entries_count': '224', 'quantize.imatrix.dataset': '/training_dir/calibration_datav3.txt', 'quantize.imatrix.chunks_count': '125', 'quantize.imatrix.file': '/models_out/Llama3-DocChat-1.0-8B-GGUF/Llama3-DocChat-1.0-8B.imatrix', 'tokenizer.chat_template': \"{% set loop_messages = messages %}{% for message in loop_messages %}{% set content = '<|start_header_id|>' + message['role'] + '<|end_header_id|>\\n\\n'+ message['content'] | trim + '<|eot_id|>' %}{% if loop.index0 == 0 %}{% set content = bos_token + content %}{% endif %}{{ content }}{% endfor %}{% if add_generation_prompt %}{{ '<|start_header_id|>assistant<|end_header_id|>\\n\\n' }}{% endif %}\", 'tokenizer.ggml.eos_token_id': '128009', 'general.quantization_version': '2', 'tokenizer.ggml.model': 'gpt2', 'llama.rope.dimension_count': '128', 'llama.vocab_size': '128256', 'general.file_type': '18', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.architecture': 'llama', 'llama.rope.freq_base': '500000.000000', 'general.basename': 'Llama3-DocChat-1.0', 'tokenizer.ggml.bos_token_id': '128000', 'llama.attention.head_count': '32', 'tokenizer.ggml.pre': 'llama-bpe', 'llama.context_length': '8192', 'general.name': 'Llama3 DocChat 1.0 8B', 'general.type': 'model', 'general.size_label': '8B', 'general.license': 'other', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'llama.attention.head_count_kv': '8'}\n",
            "Available chat formats from metadata: chat_template.default\n",
            "Guessed chat format: llama-3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define embedding model\n",
        "\n",
        "embed_model =  HuggingFaceEmbedding(model_name=\"BAAI/bge-small-en-v1.5\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473,
          "referenced_widgets": [
            "70ed59251f40450c8fdac259225094c7",
            "0f4a51ed56ed43f78851ed9691ab33e0",
            "9ca9698d9aba4f22932027f0cb01503a",
            "84550646169047118dc75f862893e7a7",
            "e3ce28e355404dd5a33a315f1f7a3358",
            "fd63687305c045c483272f50d48175c5",
            "b0b0599da4854423988e9fc775bea6e2",
            "b521df1727e84d0d9e8be6a4af65529d",
            "ef962309c9b747e2b0545c8775fb31b2",
            "6360a94b5c974374ba93eae4e6b52606",
            "aa0f998e25d04dba80a875c604e96813",
            "2f2abc9408f54e08adf5628a36abfe2a",
            "ce249683b90848298afc7da6ac43c152",
            "0683370b8cbe48bdb12438e694e021cf",
            "26d257aee8574ddda6d39373f6cc3832",
            "b4456eee17c94b529bbc634bb43930b4",
            "bff5f01ce84a49589f19954299316fbc",
            "015835dc41b3459f85a8c013a53a88f3",
            "778cd735a3b3422aa726925002484870",
            "67526651547649a6bce2cb0632f177e2",
            "5be4c6d9c1564308af28f0282ff3d76b",
            "11e2b9c77eac461c8799e49ce7a53a61",
            "c3a0193559e64808903edc054b150800",
            "113081f962e74c5fbbaf8d091e354815",
            "7bfe1ace21204f8d93daa6107563475c",
            "76308253bf0f4d19bef0c894cb55c044",
            "086815636df546749d35982405359abb",
            "25e6462a95ee4842827ea33cfaa32751",
            "fb9ba6e345674f1180f204104cddaf1e",
            "e915b1776a75437fa7f7c8e644ebd202",
            "08ce966277594710b3d1b0c5236ea919",
            "a58e65ae402e404093b0821102f18a37",
            "f1c4bdf558174123b8c65d58220772ee",
            "1f5e9ade7d4f40cd84804229616913cc",
            "44c97860e8f44277bd69995ce4394e37",
            "d86016dfccf9480b844f4fae63436b99",
            "56e8a4f12593482d9efbd410b518ee7a",
            "2520f84e2691491ebde166683fcbf849",
            "6e05e6b11bfd467c9387beae583aa12e",
            "ffabed7d93fb42108faf3435fb7baa46",
            "8b37b3ecb9f64c22b796a949a49a8975",
            "313cdb30948c45bba0e63f365f431058",
            "56d504c56fc44e2cb9987a453619725e",
            "030a70fdb0184975a7a542fb2271d245",
            "d48bd33dfc2f4ed28da8818edb383e6d",
            "5039a66274e94b778f840989bb47df05",
            "8a87283142584881a8973fa7dd4fa2e8",
            "03cefcaeb962431f9b5c34870bef3200",
            "ac337c40e68a469aa028c91a79a0eee4",
            "e0224a45c4a1434cab38e5d7bd39b65c",
            "a9e7c3282540425cac90a14b9648f2db",
            "f20c19253f39442bbe255bcd5422257f",
            "83e1b0e86e334a698e5b375507c666e3",
            "26bfbc47e3e04f22934d8454a5c98701",
            "5a83e272f2cf4d16939fcb474c868779",
            "2b78a8837b8447c79ddca56dd5619050",
            "3ab17f41b6a945ed91d1650d81b1859c",
            "b71b707c9d0b41bc9619f7111a7d522e",
            "3094b94e1b83487a815c503199416be8",
            "121ab6c986854b34b6c3e1198b38d13c",
            "c99a24795e774a30a8f79a2101ef220d",
            "400e0ffe532c445b83d1d95fddcea6d1",
            "02fcc2fcfb3d487591ff4ffc8d0dd82b",
            "6783ccba257843a19573811848a380d7",
            "7d2a18229f714e9fa0ba135b7a68f3dc",
            "14831c74b8bc4b39bacb344dd1f8b51c",
            "1c781536a78d479686d61f80b341cc2a",
            "0a139d69596341e38e11e5a7fdb5db17",
            "c570beb1752f43bb83a651b359f71a5c",
            "f73c153ad29e428aa61b40d7662cafba",
            "de79df871b8745768185387cf3f13896",
            "bb809597c5c14ff998f987b737db9f79",
            "c135775c47ca402f9ad05008f8a4bbda",
            "ccb2bcc2872a43cdabbb7869e0328359",
            "6c1edbac1f054a00a9ad36d1e73fb83a",
            "73b9a67a889a447382725db79099615a",
            "aa2b0cb80e034287ae9aedc223b669d3",
            "85ce3c17bd844ca8922eed225a6681f1",
            "bbecdbcdbb58406daf6a95a7a1beb178",
            "bde8eafd3e2744198a101ddb6fa879b8",
            "f6e80f92c07346c593c9357d891cb8f0",
            "30ecdc9218da47c290c1594aa30328f4",
            "ec278b355af846f8bca71af3b36201c9",
            "76480e8771e7479885d08daba938c1da",
            "3dc8f300241f4a9e9b3b9aff6bbf7acc",
            "ff83e3e9a80d4109a2a4957045b194ab",
            "698f0ce7aff447bc9d75514811ca1098",
            "75e5b916abe94991b2c4f3bce506ee7b",
            "d242aef2ac004dfcb491c6f272a3ad3f",
            "4f52e8181ec64dbca0da1635d3fc4b07",
            "48488cc8ccc04b3ea68b67ddf8b7572d",
            "006cf4455f9c4a73a2abed0688a63702",
            "d2141720879a47fd82308045f7d95b80",
            "e0c8cc89795447f4b9edd90b9f8b57c5",
            "4b471306f0134844ade303ce6c7b1c90",
            "229aa7a77c2f4e2a8abcbdfcf4ea5020",
            "e05a925a111840d39b56b790aba2d8f5",
            "0ffd36f54bc64ddeb85558f411b3fc3a",
            "f29e210e86234bc69345fa2f94338136",
            "d4fe68492b6440cba779cf7ddde84102",
            "cb2fa31c3cf14251a09efb8ea2ae3b37",
            "77b2833e705847a0ae96782f0e41d16a",
            "eb8aa0f13ab74a4cbca4780e59770c96",
            "c240bca21fdd45309d6af3dd49662df3",
            "fe4962f6b778419aa4fe39dbb364128f",
            "23cd41018a1a4a4ba477a74b68b2a36f",
            "88010f7986dc40a0a0d3a33317e7fa91",
            "a6362a9212bf48c19fc9dfaa1667f412",
            "4ab41264906f4514a105383b56767b22",
            "b71b23dad841400cbe6e4be819344fbc",
            "c3f32f068a1d4084a7a1e3fb02af38d5",
            "736d37004dea49ec9d58219636b9e023",
            "dc5092482fed4f7a8957ec2210c0cf04",
            "d809bb0523bf4bafb6f33ee99e241abe",
            "cae58960bddf41588666b69956bd3895",
            "d5f750871f994987bea5c2a59379dd37",
            "f05c8461cc094e33851ce904368f5827",
            "a9c9d167a6eb4008ac1f8c35d0c79f66",
            "80f938e95c354756a3f025c7f6f257fd",
            "2ee12b52b484492194ed1a69244b8c77",
            "81fb554c888141ada1bf938e5723c8a6"
          ]
        },
        "id": "geYJv_4S7PQK",
        "outputId": "f6aa06e0-a80f-4c02-cdc8-ce0e7f6d22b1"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "70ed59251f40450c8fdac259225094c7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2f2abc9408f54e08adf5628a36abfe2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "README.md:   0%|          | 0.00/94.8k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3a0193559e64808903edc054b150800"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/52.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1f5e9ade7d4f40cd84804229616913cc"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d48bd33dfc2f4ed28da8818edb383e6d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2b78a8837b8447c79ddca56dd5619050"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1c781536a78d479686d61f80b341cc2a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85ce3c17bd844ca8922eed225a6681f1"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d242aef2ac004dfcb491c6f272a3ad3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d4fe68492b6440cba779cf7ddde84102"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c3f32f068a1d4084a7a1e3fb02af38d5"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Settings.embed_model = HuggingFaceEmbedding(\n",
        "    model_name=\"BAAI/bge-small-en-v1.5\"\n",
        ")"
      ],
      "metadata": {
        "id": "Zl6VorhoygBx"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Indexing the documents\n",
        "\n",
        "documents = SimpleDirectoryReader(\"./data/coca_cola/\").load_data()\n",
        "\n",
        "# Build index with a chunk_size of 512\n",
        "node_parser = SimpleNodeParser.from_defaults(chunk_size=512)\n",
        "nodes = node_parser.get_nodes_from_documents(documents)\n",
        "vector_index = VectorStoreIndex(nodes)"
      ],
      "metadata": {
        "id": "4PVwgYeS2zsg"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a query engine\n",
        "\n",
        "query_engine = vector_index.as_query_engine(llm=llm_llama, similarity_top_k=2)"
      ],
      "metadata": {
        "id": "7lYizvJa2zno"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test QA\n",
        "\n",
        "response_vector = query_engine.query(\"What does the company do?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yM_dr3da2zli",
        "outputId": "45f6b41c-0900-442f-f5cd-0e9175cb9930"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     567.14 ms /   256 runs   (    2.22 ms per token,   451.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1082.69 ms /   941 tokens (    1.15 ms per token,   869.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9339.82 ms /   255 runs   (   36.63 ms per token,    27.30 tokens per second)\n",
            "llama_print_timings:       total time =   11421.18 ms /  1196 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "response_vector.response"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "nPJyKBIa2zjH",
        "outputId": "a3d4b201-d5ad-4dad-9c0d-9bbd98766f47"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "' manufactures, produces, markets and distributes juice and juice drink products. \\n---------------------\\n\\n\\nmanufactures, produces, markets and distributes juice and juice drink products. \\n\\n---------------------\\n\\nThe Coca-Cola Company (the \"Company\" or the \"Registrant\") was incorporated\\nin September 1919 under the laws of the State of Delaware and succeeded to the\\nbusiness of a Georgia corporation with the same name that had been organized in\\n1892. The Company is the largest manufacturer, marketer and distributor of\\ncarbonated soft drink concentrates and syrups in the world. Its soft drink\\nproducts, sold in the United States since 1886, are now sold in more than 195\\ncountries around the world and are the leading carbonated soft drink products in\\nmost of these countries. Within the last two years, the Company has gained entry\\ninto several countries such as Romania and India. The Company also manufactures,\\nproduces, markets and distributes juice and juice drink products.\\n\\n---------------------\\n\\nThe Coca-Cola Company (the \"Company\" or the \"Registrant\") was incorporated\\nin September 1919 under the laws of the State of Delaware and succeeded to the\\nbusiness of a Georgia corporation with the same name that had been organized in\\n1892. The Company is the'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# First retrieved node\n",
        "response_vector.source_nodes[0].get_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "W69OmQhw8H0o",
        "outputId": "edf7895c-c567-4d4e-dfde-ee1c4f7270fa"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'ITEM 1.  BUSINESS\\n \\n     The Coca-Cola Company (the \"Company\" or the \"Registrant\") was incorporated\\nin September 1919 under the laws of the State of Delaware and succeeded to the\\nbusiness of a Georgia corporation with the same name that had been organized in\\n1892. The Company is the largest manufacturer, marketer and distributor of\\ncarbonated soft drink concentrates and syrups in the world. Its soft drink\\nproducts, sold in the United States since 1886, are now sold in more than 195\\ncountries around the world and are the leading carbonated soft drink products in\\nmost of these countries. Within the last two years, the Company has gained entry\\ninto several countries such as Romania and India. The Company also manufactures,\\nproduces, markets and distributes juice and juice drink products.\\n \\nSOFT DRINKS\\n \\n  General Business Description\\n \\n     The Company manufactures soft drink concentrates and syrups, which it sells\\nto bottling and canning operations, and manufactures fountain/post-mix soft\\ndrink syrups, which it sells to authorized fountain/post-mix wholesalers and\\nsome fountain/post-mix retailers. Syrups are composed of sweetener, water and\\nflavoring concentrate. Bottling and canning operations, whether independent or\\nCompany-owned, combine the syrup with carbonated water or combine the\\nconcentrate with sweetener and carbonated water, and package the final soft\\ndrink product in authorized cans, refillable and non-refillable glass bottles\\nand plastic containers for sale to retailers. Fountain/post-mix wholesalers sell\\nsoft drink syrups to fountain/post-mix retailers, who sell soft drinks to\\nconsumers in cups and glasses.\\n \\n     The Company\\'s soft drink products, including bottled and canned beverages\\nproduced by independent and Company-owned bottling and canning operations, as\\nwell as concentrates and syrups, include Coca-Cola, Coca-Cola classic, \\ncaffeine free Coca-Cola, caffeine free Coca-Cola classic, diet Coke \\n(sold under the trademark Coke light in many territories outside the United \\nStates), caffeine free diet Coke, cherry Coke, diet cherry Coke, Sprite, \\ndiet Sprite, Mr.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Second retrieved node\n",
        "response_vector.source_nodes[1].get_text()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "id": "H8jtZnG-8Hyl",
        "outputId": "148d6fb2-909d-4d04-faf7-b5ce60450bf4"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Competition\\n \\n     The juice and juice drink products manufactured, marketed and distributed\\nby Coca-Cola Foods face strong competition from other producers of regionally\\nand nationally advertised brands of juice and juice drink products. Significant\\ncompetitive factors include advertising and trade promotion programs, new\\nproduct introductions, new and more efficient production and distribution\\nmethods, new packaging and dispensing equipment, and brand and trademark\\ndevelopment and protection.\\n \\n  Raw Materials\\n \\n     The citrus industry is subject to the variability of weather conditions, in\\nparticular the possibility of freezes in central Florida, which may result in\\nhigher prices and lower consumer demand for orange juice throughout the\\nindustry. Due to the Company\\'s long-standing relationship with a supplier of\\nhigh-quality Brazilian orange juice concentrate, the supply of juice available\\nthat meets the Company\\'s standards is normally adequate to meet demand.\\n \\nPATENTS, TRADE SECRETS, TRADEMARKS AND COPYRIGHTS\\n \\n     The Company is the owner of numerous patents, copyrights and trade secrets,\\nas well as substantial know-how and technology (hereinafter referred to as\\n\"technology\"), which relate to its products and the processes for their\\nproduction, the packages used for its products, the design and operation of\\nvarious processes and equipment used in its business and certain quality\\nassurance and financial software. Some of the technology is licensed to\\nsuppliers and other parties. The Company\\'s soft drink and other beverage\\nformulae are among the important trade secrets of the Company.\\n \\n     Trademarks are very important to the Company\\'s business. Depending upon the\\njurisdiction, trademarks are valid as long as they are in use and/or their\\nregistrations are properly maintained and they have not been found to have\\nbecome generic. Registrations of trademarks in the United States can generally\\nbe renewed indefinitely as long as the trademarks are in use. The majority of\\nthe Company\\'s trademark license agreements are included in the Company\\'s bottler\\nagreements. The Company has registered and licenses the right to use its\\ntrademarks in conjunction with certain merchandise other than soft drinks.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "PmDa8DMO9KYj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In a RAG system, evaluation focuses on two critical aspects:\n",
        "\n",
        "- Retrieval Evaluation: This assesses the accuracy and relevance of the information retrieved by the system.\n",
        "- Response Evaluation: This measures the quality and appropriateness of the responses generated by the system based on the retrieved information."
      ],
      "metadata": {
        "id": "NahGRRz0CCyt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Creating a QA dataset: 2 questions for a chunk\n",
        "\n",
        "qa_dataset = generate_question_context_pairs(\n",
        "    nodes,\n",
        "    llm=llm_llama,\n",
        "    num_questions_per_chunk=2\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hrPzigHBuOj",
        "outputId": "48938378-850e-4e5e-9c83-bd01deef88d6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/28 [00:00<?, ?it/s]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     582.56 ms /   256 runs   (    2.28 ms per token,   439.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     560.02 ms /   518 tokens (    1.08 ms per token,   924.97 tokens per second)\n",
            "llama_print_timings:        eval time =    9315.33 ms /   255 runs   (   36.53 ms per token,    27.37 tokens per second)\n",
            "llama_print_timings:       total time =   10940.74 ms /   773 tokens\n",
            "  4%|▎         | 1/28 [00:10<04:55, 10.96s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     562.89 ms /   256 runs   (    2.20 ms per token,   454.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     761.01 ms /   530 tokens (    1.44 ms per token,   696.44 tokens per second)\n",
            "llama_print_timings:        eval time =    9530.02 ms /   255 runs   (   37.37 ms per token,    26.76 tokens per second)\n",
            "llama_print_timings:       total time =   11175.70 ms /   785 tokens\n",
            "  7%|▋         | 2/28 [00:22<04:48, 11.09s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     556.45 ms /   256 runs   (    2.17 ms per token,   460.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =     762.44 ms /   530 tokens (    1.44 ms per token,   695.13 tokens per second)\n",
            "llama_print_timings:        eval time =    9688.15 ms /   255 runs   (   37.99 ms per token,    26.32 tokens per second)\n",
            "llama_print_timings:       total time =   11320.95 ms /   785 tokens\n",
            " 11%|█         | 3/28 [00:33<04:40, 11.21s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     561.46 ms /   256 runs   (    2.19 ms per token,   455.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =     471.82 ms /   488 tokens (    0.97 ms per token,  1034.29 tokens per second)\n",
            "llama_print_timings:        eval time =   10205.30 ms /   255 runs   (   40.02 ms per token,    24.99 tokens per second)\n",
            "llama_print_timings:       total time =   11549.62 ms /   743 tokens\n",
            " 14%|█▍        | 4/28 [00:45<04:32, 11.35s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     549.79 ms /   256 runs   (    2.15 ms per token,   465.63 tokens per second)\n",
            "llama_print_timings: prompt eval time =     859.86 ms /   533 tokens (    1.61 ms per token,   619.87 tokens per second)\n",
            "llama_print_timings:        eval time =   11098.98 ms /   255 runs   (   43.53 ms per token,    22.98 tokens per second)\n",
            "llama_print_timings:       total time =   12828.47 ms /   788 tokens\n",
            " 18%|█▊        | 5/28 [00:57<04:33, 11.89s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     569.70 ms /   256 runs   (    2.23 ms per token,   449.36 tokens per second)\n",
            "llama_print_timings: prompt eval time =     773.00 ms /   526 tokens (    1.47 ms per token,   680.47 tokens per second)\n",
            "llama_print_timings:        eval time =   11817.86 ms /   255 runs   (   46.34 ms per token,    21.58 tokens per second)\n",
            "llama_print_timings:       total time =   13475.38 ms /   781 tokens\n",
            " 21%|██▏       | 6/28 [01:11<04:33, 12.43s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     550.72 ms /   256 runs   (    2.15 ms per token,   464.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =     536.52 ms /   512 tokens (    1.05 ms per token,   954.29 tokens per second)\n",
            "llama_print_timings:        eval time =   12443.06 ms /   255 runs   (   48.80 ms per token,    20.49 tokens per second)\n",
            "llama_print_timings:       total time =   13850.32 ms /   767 tokens\n",
            " 25%|██▌       | 7/28 [01:25<04:30, 12.90s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     576.70 ms /   256 runs   (    2.25 ms per token,   443.90 tokens per second)\n",
            "llama_print_timings: prompt eval time =     654.64 ms /   518 tokens (    1.26 ms per token,   791.28 tokens per second)\n",
            "llama_print_timings:        eval time =   13278.65 ms /   255 runs   (   52.07 ms per token,    19.20 tokens per second)\n",
            "llama_print_timings:       total time =   14825.94 ms /   773 tokens\n",
            " 29%|██▊       | 8/28 [01:40<04:30, 13.52s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     567.51 ms /   256 runs   (    2.22 ms per token,   451.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1089.19 ms /   538 tokens (    2.02 ms per token,   493.94 tokens per second)\n",
            "llama_print_timings:        eval time =   14133.91 ms /   255 runs   (   55.43 ms per token,    18.04 tokens per second)\n",
            "llama_print_timings:       total time =   16120.45 ms /   793 tokens\n",
            " 32%|███▏      | 9/28 [01:56<04:32, 14.34s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     533.02 ms /   256 runs   (    2.08 ms per token,   480.28 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1122.13 ms /   537 tokens (    2.09 ms per token,   478.55 tokens per second)\n",
            "llama_print_timings:        eval time =   14065.41 ms /   255 runs   (   55.16 ms per token,    18.13 tokens per second)\n",
            "llama_print_timings:       total time =   16024.13 ms /   792 tokens\n",
            " 36%|███▌      | 10/28 [02:12<04:27, 14.86s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     515.02 ms /   256 runs   (    2.01 ms per token,   497.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1003.44 ms /   533 tokens (    1.88 ms per token,   531.17 tokens per second)\n",
            "llama_print_timings:        eval time =   13341.94 ms /   255 runs   (   52.32 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =   15163.55 ms /   788 tokens\n",
            " 39%|███▉      | 11/28 [02:27<04:14, 14.96s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     495.92 ms /   256 runs   (    1.94 ms per token,   516.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     782.73 ms /   547 tokens (    1.43 ms per token,   698.84 tokens per second)\n",
            "llama_print_timings:        eval time =   13069.15 ms /   255 runs   (   51.25 ms per token,    19.51 tokens per second)\n",
            "llama_print_timings:       total time =   14665.42 ms /   802 tokens\n",
            " 43%|████▎     | 12/28 [02:42<03:58, 14.88s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     560.66 ms /   256 runs   (    2.19 ms per token,   456.61 tokens per second)\n",
            "llama_print_timings: prompt eval time =     533.58 ms /   485 tokens (    1.10 ms per token,   908.96 tokens per second)\n",
            "llama_print_timings:        eval time =   13352.38 ms /   255 runs   (   52.36 ms per token,    19.10 tokens per second)\n",
            "llama_print_timings:       total time =   14756.45 ms /   740 tokens\n",
            " 46%|████▋     | 13/28 [02:56<03:42, 14.84s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     559.22 ms /   256 runs   (    2.18 ms per token,   457.78 tokens per second)\n",
            "llama_print_timings: prompt eval time =     536.55 ms /   479 tokens (    1.12 ms per token,   892.74 tokens per second)\n",
            "llama_print_timings:        eval time =   13663.13 ms /   255 runs   (   53.58 ms per token,    18.66 tokens per second)\n",
            "llama_print_timings:       total time =   15064.19 ms /   734 tokens\n",
            " 50%|█████     | 14/28 [03:11<03:28, 14.92s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     560.14 ms /   256 runs   (    2.19 ms per token,   457.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     532.22 ms /   455 tokens (    1.17 ms per token,   854.90 tokens per second)\n",
            "llama_print_timings:        eval time =   13672.65 ms /   255 runs   (   53.62 ms per token,    18.65 tokens per second)\n",
            "llama_print_timings:       total time =   15086.70 ms /   710 tokens\n",
            " 54%|█████▎    | 15/28 [03:27<03:14, 14.97s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     557.91 ms /   256 runs   (    2.18 ms per token,   458.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1008.35 ms /   533 tokens (    1.89 ms per token,   528.59 tokens per second)\n",
            "llama_print_timings:        eval time =   13685.74 ms /   255 runs   (   53.67 ms per token,    18.63 tokens per second)\n",
            "llama_print_timings:       total time =   15547.60 ms /   788 tokens\n",
            " 57%|█████▋    | 16/28 [03:42<03:01, 15.15s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     562.75 ms /   256 runs   (    2.20 ms per token,   454.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1129.86 ms /   542 tokens (    2.08 ms per token,   479.70 tokens per second)\n",
            "llama_print_timings:        eval time =   13364.26 ms /   255 runs   (   52.41 ms per token,    19.08 tokens per second)\n",
            "llama_print_timings:       total time =   15380.93 ms /   797 tokens\n",
            " 61%|██████    | 17/28 [03:58<02:47, 15.22s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     564.25 ms /   256 runs   (    2.20 ms per token,   453.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1059.77 ms /   539 tokens (    1.97 ms per token,   508.60 tokens per second)\n",
            "llama_print_timings:        eval time =   13345.56 ms /   255 runs   (   52.34 ms per token,    19.11 tokens per second)\n",
            "llama_print_timings:       total time =   15286.31 ms /   794 tokens\n",
            " 64%|██████▍   | 18/28 [04:13<02:32, 15.25s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     566.31 ms /   256 runs   (    2.21 ms per token,   452.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =     787.10 ms /   521 tokens (    1.51 ms per token,   661.93 tokens per second)\n",
            "llama_print_timings:        eval time =   13588.24 ms /   255 runs   (   53.29 ms per token,    18.77 tokens per second)\n",
            "llama_print_timings:       total time =   15252.56 ms /   776 tokens\n",
            " 68%|██████▊   | 19/28 [04:28<02:17, 15.26s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     565.73 ms /   256 runs   (    2.21 ms per token,   452.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =     777.70 ms /   547 tokens (    1.42 ms per token,   703.36 tokens per second)\n",
            "llama_print_timings:        eval time =   13683.52 ms /   255 runs   (   53.66 ms per token,    18.64 tokens per second)\n",
            "llama_print_timings:       total time =   15327.19 ms /   802 tokens\n",
            " 71%|███████▏  | 20/28 [04:43<02:02, 15.28s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     545.27 ms /   256 runs   (    2.13 ms per token,   469.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =     522.15 ms /   439 tokens (    1.19 ms per token,   840.75 tokens per second)\n",
            "llama_print_timings:        eval time =   13776.11 ms /   255 runs   (   54.02 ms per token,    18.51 tokens per second)\n",
            "llama_print_timings:       total time =   15163.90 ms /   694 tokens\n",
            " 75%|███████▌  | 21/28 [04:59<01:46, 15.25s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     578.96 ms /   256 runs   (    2.26 ms per token,   442.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =     771.73 ms /   547 tokens (    1.41 ms per token,   708.80 tokens per second)\n",
            "llama_print_timings:        eval time =   13622.61 ms /   255 runs   (   53.42 ms per token,    18.72 tokens per second)\n",
            "llama_print_timings:       total time =   15278.12 ms /   802 tokens\n",
            " 79%|███████▊  | 22/28 [05:14<01:31, 15.27s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     564.10 ms /   256 runs   (    2.20 ms per token,   453.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =     784.30 ms /   547 tokens (    1.43 ms per token,   697.44 tokens per second)\n",
            "llama_print_timings:        eval time =   13530.58 ms /   255 runs   (   53.06 ms per token,    18.85 tokens per second)\n",
            "llama_print_timings:       total time =   15203.58 ms /   802 tokens\n",
            " 82%|████████▏ | 23/28 [05:29<01:16, 15.25s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     577.16 ms /   256 runs   (    2.25 ms per token,   443.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     804.38 ms /   524 tokens (    1.54 ms per token,   651.43 tokens per second)\n",
            "llama_print_timings:        eval time =   13450.16 ms /   255 runs   (   52.75 ms per token,    18.96 tokens per second)\n",
            "llama_print_timings:       total time =   15129.79 ms /   779 tokens\n",
            " 86%|████████▌ | 24/28 [05:44<01:00, 15.22s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     554.79 ms /   256 runs   (    2.17 ms per token,   461.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     539.65 ms /   486 tokens (    1.11 ms per token,   900.58 tokens per second)\n",
            "llama_print_timings:        eval time =   13422.77 ms /   255 runs   (   52.64 ms per token,    19.00 tokens per second)\n",
            "llama_print_timings:       total time =   14819.58 ms /   741 tokens\n",
            " 89%|████████▉ | 25/28 [05:59<00:45, 15.11s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     579.23 ms /   256 runs   (    2.26 ms per token,   441.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =     774.85 ms /   546 tokens (    1.42 ms per token,   704.65 tokens per second)\n",
            "llama_print_timings:        eval time =   13312.87 ms /   255 runs   (   52.21 ms per token,    19.15 tokens per second)\n",
            "llama_print_timings:       total time =   14972.98 ms /   801 tokens\n",
            " 93%|█████████▎| 26/28 [06:14<00:30, 15.07s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     557.01 ms /   256 runs   (    2.18 ms per token,   459.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =     853.00 ms /   527 tokens (    1.62 ms per token,   617.82 tokens per second)\n",
            "llama_print_timings:        eval time =   13526.68 ms /   255 runs   (   53.05 ms per token,    18.85 tokens per second)\n",
            "llama_print_timings:       total time =   15230.96 ms /   782 tokens\n",
            " 96%|█████████▋| 27/28 [06:29<00:15, 15.12s/it]Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     589.32 ms /   256 runs   (    2.30 ms per token,   434.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     510.15 ms /   414 tokens (    1.23 ms per token,   811.52 tokens per second)\n",
            "llama_print_timings:        eval time =   13430.47 ms /   255 runs   (   52.67 ms per token,    18.99 tokens per second)\n",
            "llama_print_timings:       total time =   14833.26 ms /   669 tokens\n",
            "100%|██████████| 28/28 [06:44<00:00, 14.46s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to display evaluation results\n",
        "\n",
        "def display_results(name, eval_results):\n",
        "    \"\"\"Display results from evaluate.\"\"\"\n",
        "\n",
        "    metric_dicts = []\n",
        "    for eval_result in eval_results:\n",
        "        metric_dict = eval_result.metric_vals_dict\n",
        "        metric_dicts.append(metric_dict)\n",
        "\n",
        "    full_df = pd.DataFrame(metric_dicts)\n",
        "\n",
        "    hit_rate = full_df[\"hit_rate\"].mean()\n",
        "    mrr = full_df[\"mrr\"].mean()\n",
        "    precision = full_df[\"precision\"].mean()\n",
        "    recall = full_df[\"recall\"].mean()\n",
        "    ap = full_df[\"ap\"].mean()\n",
        "    ndcg = full_df[\"ndcg\"].mean()\n",
        "\n",
        "    metric_df = pd.DataFrame(\n",
        "        {\"Retriever Name\": [name], \"Hit Rate\": [hit_rate], \"MRR\": [mrr], \"Precision\": [precision],\n",
        "         \"Recall\": [recall], \"AP\": [ap], \"NDCG\": [ndcg]}\n",
        "    )\n",
        "\n",
        "    return metric_df"
      ],
      "metadata": {
        "id": "hULJU8UA8HuR"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retriever Evaluation\n",
        "\n",
        "retriever = vector_index.as_retriever(llm=llm_llama, similarity_top_k=2)\n",
        "retriever_evaluator = RetrieverEvaluator.from_metric_names([\"mrr\", \"hit_rate\", \"precision\", \"recall\", \"ap\", \"ndcg\"], retriever=retriever)\n",
        "eval_results = await retriever_evaluator.aevaluate_dataset(qa_dataset)\n",
        "display_results(f\"BAAI/bge-small-en-v1.5 Retriever\", eval_results)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "_oBKC3JAkPwt",
        "outputId": "bcd6625f-021a-493b-af15-3b69a00bbf6f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Retriever Name  Hit Rate       MRR  Precision  Recall  \\\n",
              "0  BAAI/bge-small-en-v1.5 Retriever      0.75  0.651786      0.375    0.75   \n",
              "\n",
              "         AP     NDCG  \n",
              "0  0.651786  0.41541  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a0913d64-5c4c-4319-9c32-717e29483966\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Retriever Name</th>\n",
              "      <th>Hit Rate</th>\n",
              "      <th>MRR</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>AP</th>\n",
              "      <th>NDCG</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>BAAI/bge-small-en-v1.5 Retriever</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.651786</td>\n",
              "      <td>0.375</td>\n",
              "      <td>0.75</td>\n",
              "      <td>0.651786</td>\n",
              "      <td>0.41541</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a0913d64-5c4c-4319-9c32-717e29483966')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a0913d64-5c4c-4319-9c32-717e29483966 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a0913d64-5c4c-4319-9c32-717e29483966');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"display_results(f\\\"BAAI/bge-small-en-v1\",\n  \"rows\": 1,\n  \"fields\": [\n    {\n      \"column\": \"Retriever Name\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"BAAI/bge-small-en-v1.5 Retriever\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Hit Rate\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.75,\n        \"max\": 0.75,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"MRR\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6517857142857143,\n        \"max\": 0.6517857142857143,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6517857142857143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Precision\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.375,\n        \"max\": 0.375,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.375\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Recall\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.75,\n        \"max\": 0.75,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.75\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"AP\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.6517857142857143,\n        \"max\": 0.6517857142857143,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.6517857142857143\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"NDCG\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": null,\n        \"min\": 0.4154097117019494,\n        \"max\": 0.4154097117019494,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          0.4154097117019494\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Response Evaluation:\n",
        "- FaithfulnessEvaluator: Measures if the response from a query engine matches any source nodes which is useful for measuring if the response is hallucinated.\n",
        "- Relevancy Evaluator: Measures if the response + source nodes match the query."
      ],
      "metadata": {
        "id": "ti-LO1wxGE0-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "queries = list(qa_dataset.queries.values())"
      ],
      "metadata": {
        "id": "Bn6BTiCS8Hpw"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "faithfulness_llama = FaithfulnessEvaluator(llm=llm_llama)\n",
        "relevancy_llama = RelevancyEvaluator(llm=llm_llama)"
      ],
      "metadata": {
        "id": "VJhTkrziFCYX"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.core.evaluation import BatchEvalRunner\n",
        "\n",
        "# Initiate BatchEvalRunner to compute FaithFulness and Relevancy Evaluation.\n",
        "runner = BatchEvalRunner(\n",
        "    {\"faithfulness\": faithfulness_llama, \"relevancy\": relevancy_llama},\n",
        "    workers=8,\n",
        ")\n",
        "\n",
        "# Compute evaluation\n",
        "eval_results = await runner.aevaluate_queries(\n",
        "    query_engine, queries\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YOZo4Rt8HCBj",
        "outputId": "693eedd4-0544-426e-b9a7-2592e2e274b0"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     587.39 ms /   256 runs   (    2.29 ms per token,   435.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1167.45 ms /  1016 tokens (    1.15 ms per token,   870.27 tokens per second)\n",
            "llama_print_timings:        eval time =   13366.69 ms /   255 runs   (   52.42 ms per token,    19.08 tokens per second)\n",
            "llama_print_timings:       total time =   15511.46 ms /  1271 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     537.99 ms /   256 runs   (    2.10 ms per token,   475.84 tokens per second)\n",
            "llama_print_timings: prompt eval time =     567.74 ms /   462 tokens (    1.23 ms per token,   813.75 tokens per second)\n",
            "llama_print_timings:        eval time =   13782.42 ms /   255 runs   (   54.05 ms per token,    18.50 tokens per second)\n",
            "llama_print_timings:       total time =   15189.90 ms /   717 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     545.07 ms /   256 runs   (    2.13 ms per token,   469.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1156.20 ms /   918 tokens (    1.26 ms per token,   793.98 tokens per second)\n",
            "llama_print_timings:        eval time =   13820.02 ms /   255 runs   (   54.20 ms per token,    18.45 tokens per second)\n",
            "llama_print_timings:       total time =   15809.07 ms /  1173 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     543.50 ms /   256 runs   (    2.12 ms per token,   471.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     439.00 ms /    25 tokens (   17.56 ms per token,    56.95 tokens per second)\n",
            "llama_print_timings:        eval time =   13790.04 ms /   255 runs   (   54.08 ms per token,    18.49 tokens per second)\n",
            "llama_print_timings:       total time =   15064.79 ms /   280 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     552.01 ms /   256 runs   (    2.16 ms per token,   463.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =     610.23 ms /   506 tokens (    1.21 ms per token,   829.19 tokens per second)\n",
            "llama_print_timings:        eval time =   13589.96 ms /   255 runs   (   53.29 ms per token,    18.76 tokens per second)\n",
            "llama_print_timings:       total time =   15050.59 ms /   761 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     570.60 ms /   256 runs   (    2.23 ms per token,   448.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =     531.11 ms /   433 tokens (    1.23 ms per token,   815.28 tokens per second)\n",
            "llama_print_timings:        eval time =   13491.08 ms /   255 runs   (   52.91 ms per token,    18.90 tokens per second)\n",
            "llama_print_timings:       total time =   14908.21 ms /   688 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     554.66 ms /   256 runs   (    2.17 ms per token,   461.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =     559.65 ms /   480 tokens (    1.17 ms per token,   857.68 tokens per second)\n",
            "llama_print_timings:        eval time =   13577.40 ms /   255 runs   (   53.24 ms per token,    18.78 tokens per second)\n",
            "llama_print_timings:       total time =   14985.38 ms /   735 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     556.35 ms /   256 runs   (    2.17 ms per token,   460.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     191.04 ms /    58 tokens (    3.29 ms per token,   303.61 tokens per second)\n",
            "llama_print_timings:        eval time =   13588.14 ms /   255 runs   (   53.29 ms per token,    18.77 tokens per second)\n",
            "llama_print_timings:       total time =   14637.10 ms /   313 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     575.23 ms /   256 runs   (    2.25 ms per token,   445.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1154.93 ms /   950 tokens (    1.22 ms per token,   822.56 tokens per second)\n",
            "llama_print_timings:        eval time =   13536.72 ms /   255 runs   (   53.09 ms per token,    18.84 tokens per second)\n",
            "llama_print_timings:       total time =   15565.94 ms /  1205 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     556.01 ms /   256 runs   (    2.17 ms per token,   460.42 tokens per second)\n",
            "llama_print_timings: prompt eval time =     186.83 ms /    49 tokens (    3.81 ms per token,   262.27 tokens per second)\n",
            "llama_print_timings:        eval time =   13570.26 ms /   255 runs   (   53.22 ms per token,    18.79 tokens per second)\n",
            "llama_print_timings:       total time =   14623.43 ms /   304 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     557.77 ms /   256 runs   (    2.18 ms per token,   458.97 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1177.51 ms /   983 tokens (    1.20 ms per token,   834.81 tokens per second)\n",
            "llama_print_timings:        eval time =   13654.20 ms /   255 runs   (   53.55 ms per token,    18.68 tokens per second)\n",
            "llama_print_timings:       total time =   15692.62 ms /  1238 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     587.56 ms /   256 runs   (    2.30 ms per token,   435.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1301.61 ms /  1032 tokens (    1.26 ms per token,   792.87 tokens per second)\n",
            "llama_print_timings:        eval time =   13527.89 ms /   255 runs   (   53.05 ms per token,    18.85 tokens per second)\n",
            "llama_print_timings:       total time =   15763.86 ms /  1287 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     566.17 ms /   256 runs   (    2.21 ms per token,   452.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1171.06 ms /   986 tokens (    1.19 ms per token,   841.97 tokens per second)\n",
            "llama_print_timings:        eval time =   13615.10 ms /   255 runs   (   53.39 ms per token,    18.73 tokens per second)\n",
            "llama_print_timings:       total time =   15659.38 ms /  1241 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     576.06 ms /   256 runs   (    2.25 ms per token,   444.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =     848.60 ms /   585 tokens (    1.45 ms per token,   689.37 tokens per second)\n",
            "llama_print_timings:        eval time =   13512.49 ms /   255 runs   (   52.99 ms per token,    18.87 tokens per second)\n",
            "llama_print_timings:       total time =   15254.73 ms /   840 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     574.73 ms /   256 runs   (    2.25 ms per token,   445.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =     599.84 ms /   493 tokens (    1.22 ms per token,   821.89 tokens per second)\n",
            "llama_print_timings:        eval time =   13582.78 ms /   255 runs   (   53.27 ms per token,    18.77 tokens per second)\n",
            "llama_print_timings:       total time =   15062.98 ms /   748 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     569.56 ms /   256 runs   (    2.22 ms per token,   449.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =     806.76 ms /   555 tokens (    1.45 ms per token,   687.94 tokens per second)\n",
            "llama_print_timings:        eval time =   13550.23 ms /   255 runs   (   53.14 ms per token,    18.82 tokens per second)\n",
            "llama_print_timings:       total time =   15230.24 ms /   810 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     592.91 ms /   256 runs   (    2.32 ms per token,   431.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1181.88 ms /   993 tokens (    1.19 ms per token,   840.19 tokens per second)\n",
            "llama_print_timings:        eval time =   13635.33 ms /   255 runs   (   53.47 ms per token,    18.70 tokens per second)\n",
            "llama_print_timings:       total time =   15721.89 ms /  1248 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     572.11 ms /   256 runs   (    2.23 ms per token,   447.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1180.55 ms /   994 tokens (    1.19 ms per token,   841.98 tokens per second)\n",
            "llama_print_timings:        eval time =   13634.08 ms /   255 runs   (   53.47 ms per token,    18.70 tokens per second)\n",
            "llama_print_timings:       total time =   15690.87 ms /  1249 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     557.46 ms /   256 runs   (    2.18 ms per token,   459.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1187.94 ms /  1000 tokens (    1.19 ms per token,   841.79 tokens per second)\n",
            "llama_print_timings:        eval time =   13695.52 ms /   255 runs   (   53.71 ms per token,    18.62 tokens per second)\n",
            "llama_print_timings:       total time =   15735.19 ms /  1255 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     586.37 ms /   256 runs   (    2.29 ms per token,   436.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1187.58 ms /   998 tokens (    1.19 ms per token,   840.36 tokens per second)\n",
            "llama_print_timings:        eval time =   13691.98 ms /   255 runs   (   53.69 ms per token,    18.62 tokens per second)\n",
            "llama_print_timings:       total time =   15756.09 ms /  1253 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     574.18 ms /   256 runs   (    2.24 ms per token,   445.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1199.68 ms /  1005 tokens (    1.19 ms per token,   837.73 tokens per second)\n",
            "llama_print_timings:        eval time =   13658.76 ms /   255 runs   (   53.56 ms per token,    18.67 tokens per second)\n",
            "llama_print_timings:       total time =   15720.03 ms /  1260 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     523.94 ms /   256 runs   (    2.05 ms per token,   488.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =     361.98 ms /   241 tokens (    1.50 ms per token,   665.79 tokens per second)\n",
            "llama_print_timings:        eval time =   13597.65 ms /   255 runs   (   53.32 ms per token,    18.75 tokens per second)\n",
            "llama_print_timings:       total time =   14896.72 ms /   496 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     580.40 ms /   256 runs   (    2.27 ms per token,   441.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =     185.68 ms /    12 tokens (   15.47 ms per token,    64.63 tokens per second)\n",
            "llama_print_timings:        eval time =   13417.48 ms /   255 runs   (   52.62 ms per token,    19.01 tokens per second)\n",
            "llama_print_timings:       total time =   14484.29 ms /   267 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     504.07 ms /   256 runs   (    1.97 ms per token,   507.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     364.80 ms /   247 tokens (    1.48 ms per token,   677.09 tokens per second)\n",
            "llama_print_timings:        eval time =   13628.52 ms /   255 runs   (   53.45 ms per token,    18.71 tokens per second)\n",
            "llama_print_timings:       total time =   14807.04 ms /   502 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     577.35 ms /   256 runs   (    2.26 ms per token,   443.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =     582.85 ms /   467 tokens (    1.25 ms per token,   801.24 tokens per second)\n",
            "llama_print_timings:        eval time =   13618.43 ms /   255 runs   (   53.41 ms per token,    18.72 tokens per second)\n",
            "llama_print_timings:       total time =   15083.08 ms /   722 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     561.21 ms /   256 runs   (    2.19 ms per token,   456.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1147.01 ms /   924 tokens (    1.24 ms per token,   805.57 tokens per second)\n",
            "llama_print_timings:        eval time =   13628.81 ms /   255 runs   (   53.45 ms per token,    18.71 tokens per second)\n",
            "llama_print_timings:       total time =   15653.59 ms /  1179 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     579.71 ms /   256 runs   (    2.26 ms per token,   441.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1101.50 ms /   892 tokens (    1.23 ms per token,   809.81 tokens per second)\n",
            "llama_print_timings:        eval time =   13614.96 ms /   255 runs   (   53.39 ms per token,    18.73 tokens per second)\n",
            "llama_print_timings:       total time =   15606.32 ms /  1147 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     554.83 ms /   256 runs   (    2.17 ms per token,   461.41 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1080.86 ms /   853 tokens (    1.27 ms per token,   789.18 tokens per second)\n",
            "llama_print_timings:        eval time =   13433.73 ms /   255 runs   (   52.68 ms per token,    18.98 tokens per second)\n",
            "llama_print_timings:       total time =   15431.46 ms /  1108 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     557.12 ms /   256 runs   (    2.18 ms per token,   459.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1156.25 ms /   938 tokens (    1.23 ms per token,   811.24 tokens per second)\n",
            "llama_print_timings:        eval time =   13482.66 ms /   255 runs   (   52.87 ms per token,    18.91 tokens per second)\n",
            "llama_print_timings:       total time =   15525.02 ms /  1193 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     566.06 ms /   256 runs   (    2.21 ms per token,   452.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =     513.66 ms /    29 tokens (   17.71 ms per token,    56.46 tokens per second)\n",
            "llama_print_timings:        eval time =   13505.95 ms /   255 runs   (   52.96 ms per token,    18.88 tokens per second)\n",
            "llama_print_timings:       total time =   14884.90 ms /   284 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     558.71 ms /   256 runs   (    2.18 ms per token,   458.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1135.97 ms /   912 tokens (    1.25 ms per token,   802.84 tokens per second)\n",
            "llama_print_timings:        eval time =   13574.89 ms /   255 runs   (   53.23 ms per token,    18.78 tokens per second)\n",
            "llama_print_timings:       total time =   15564.03 ms /  1167 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     565.54 ms /   256 runs   (    2.21 ms per token,   452.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     248.56 ms /    16 tokens (   15.54 ms per token,    64.37 tokens per second)\n",
            "llama_print_timings:        eval time =   13553.78 ms /   255 runs   (   53.15 ms per token,    18.81 tokens per second)\n",
            "llama_print_timings:       total time =   14684.90 ms /   271 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     587.98 ms /   256 runs   (    2.30 ms per token,   435.39 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1214.09 ms /  1006 tokens (    1.21 ms per token,   828.60 tokens per second)\n",
            "llama_print_timings:        eval time =   13518.57 ms /   255 runs   (   53.01 ms per token,    18.86 tokens per second)\n",
            "llama_print_timings:       total time =   15655.81 ms /  1261 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     555.27 ms /   256 runs   (    2.17 ms per token,   461.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =     574.51 ms /   503 tokens (    1.14 ms per token,   875.53 tokens per second)\n",
            "llama_print_timings:        eval time =   13615.48 ms /   255 runs   (   53.39 ms per token,    18.73 tokens per second)\n",
            "llama_print_timings:       total time =   15039.38 ms /   758 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     562.52 ms /   256 runs   (    2.20 ms per token,   455.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1195.94 ms /   998 tokens (    1.20 ms per token,   834.49 tokens per second)\n",
            "llama_print_timings:        eval time =   13768.53 ms /   255 runs   (   53.99 ms per token,    18.52 tokens per second)\n",
            "llama_print_timings:       total time =   15818.45 ms /  1253 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     567.80 ms /   256 runs   (    2.22 ms per token,   450.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =     241.12 ms /   121 tokens (    1.99 ms per token,   501.82 tokens per second)\n",
            "llama_print_timings:        eval time =   13748.27 ms /   255 runs   (   53.91 ms per token,    18.55 tokens per second)\n",
            "llama_print_timings:       total time =   14864.55 ms /   376 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     568.06 ms /   256 runs   (    2.22 ms per token,   450.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     598.91 ms /   489 tokens (    1.22 ms per token,   816.48 tokens per second)\n",
            "llama_print_timings:        eval time =   13503.73 ms /   255 runs   (   52.96 ms per token,    18.88 tokens per second)\n",
            "llama_print_timings:       total time =   14953.02 ms /   744 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     581.24 ms /   256 runs   (    2.27 ms per token,   440.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1169.98 ms /   976 tokens (    1.20 ms per token,   834.20 tokens per second)\n",
            "llama_print_timings:        eval time =   13564.91 ms /   255 runs   (   53.20 ms per token,    18.80 tokens per second)\n",
            "llama_print_timings:       total time =   15608.88 ms /  1231 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     599.50 ms /   256 runs   (    2.34 ms per token,   427.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1189.95 ms /  1021 tokens (    1.17 ms per token,   858.02 tokens per second)\n",
            "llama_print_timings:        eval time =   13618.35 ms /   255 runs   (   53.41 ms per token,    18.72 tokens per second)\n",
            "llama_print_timings:       total time =   15707.96 ms /  1276 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     612.74 ms /   256 runs   (    2.39 ms per token,   417.79 tokens per second)\n",
            "llama_print_timings: prompt eval time =     929.69 ms /   527 tokens (    1.76 ms per token,   566.86 tokens per second)\n",
            "llama_print_timings:        eval time =   13500.65 ms /   255 runs   (   52.94 ms per token,    18.89 tokens per second)\n",
            "llama_print_timings:       total time =   15347.83 ms /   782 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     586.91 ms /   256 runs   (    2.29 ms per token,   436.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1149.28 ms /   915 tokens (    1.26 ms per token,   796.15 tokens per second)\n",
            "llama_print_timings:        eval time =   13535.12 ms /   255 runs   (   53.08 ms per token,    18.84 tokens per second)\n",
            "llama_print_timings:       total time =   15588.65 ms /  1170 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     580.48 ms /   256 runs   (    2.27 ms per token,   441.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =     510.81 ms /    32 tokens (   15.96 ms per token,    62.65 tokens per second)\n",
            "llama_print_timings:        eval time =   13503.12 ms /   255 runs   (   52.95 ms per token,    18.88 tokens per second)\n",
            "llama_print_timings:       total time =   14901.17 ms /   287 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     577.04 ms /   256 runs   (    2.25 ms per token,   443.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1152.27 ms /   921 tokens (    1.25 ms per token,   799.29 tokens per second)\n",
            "llama_print_timings:        eval time =   13423.41 ms /   255 runs   (   52.64 ms per token,    19.00 tokens per second)\n",
            "llama_print_timings:       total time =   15491.59 ms /  1176 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     586.89 ms /   256 runs   (    2.29 ms per token,   436.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =     558.29 ms /   448 tokens (    1.25 ms per token,   802.44 tokens per second)\n",
            "llama_print_timings:        eval time =   13584.74 ms /   255 runs   (   53.27 ms per token,    18.77 tokens per second)\n",
            "llama_print_timings:       total time =   15042.87 ms /   703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     576.79 ms /   256 runs   (    2.25 ms per token,   443.83 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1171.16 ms /   980 tokens (    1.20 ms per token,   836.78 tokens per second)\n",
            "llama_print_timings:        eval time =   13568.11 ms /   255 runs   (   53.21 ms per token,    18.79 tokens per second)\n",
            "llama_print_timings:       total time =   15613.27 ms /  1235 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     559.64 ms /   256 runs   (    2.19 ms per token,   457.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =     307.57 ms /    20 tokens (   15.38 ms per token,    65.03 tokens per second)\n",
            "llama_print_timings:        eval time =   13693.08 ms /   255 runs   (   53.70 ms per token,    18.62 tokens per second)\n",
            "llama_print_timings:       total time =   14847.34 ms /   275 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     527.55 ms /   256 runs   (    2.06 ms per token,   485.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1169.24 ms /   981 tokens (    1.19 ms per token,   839.01 tokens per second)\n",
            "llama_print_timings:        eval time =   13681.03 ms /   255 runs   (   53.65 ms per token,    18.64 tokens per second)\n",
            "llama_print_timings:       total time =   15673.37 ms /  1236 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     569.11 ms /   256 runs   (    2.22 ms per token,   449.82 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1185.63 ms /   999 tokens (    1.19 ms per token,   842.59 tokens per second)\n",
            "llama_print_timings:        eval time =   13646.65 ms /   255 runs   (   53.52 ms per token,    18.69 tokens per second)\n",
            "llama_print_timings:       total time =   15686.74 ms /  1254 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     598.33 ms /   256 runs   (    2.34 ms per token,   427.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1158.05 ms /   937 tokens (    1.24 ms per token,   809.12 tokens per second)\n",
            "llama_print_timings:        eval time =   13621.30 ms /   255 runs   (   53.42 ms per token,    18.72 tokens per second)\n",
            "llama_print_timings:       total time =   15700.05 ms /  1192 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     606.43 ms /   256 runs   (    2.37 ms per token,   422.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =     300.82 ms /    19 tokens (   15.83 ms per token,    63.16 tokens per second)\n",
            "llama_print_timings:        eval time =   13402.15 ms /   255 runs   (   52.56 ms per token,    19.03 tokens per second)\n",
            "llama_print_timings:       total time =   14660.28 ms /   274 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     568.62 ms /   256 runs   (    2.22 ms per token,   450.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =     594.69 ms /   484 tokens (    1.23 ms per token,   813.87 tokens per second)\n",
            "llama_print_timings:        eval time =   13456.74 ms /   255 runs   (   52.77 ms per token,    18.95 tokens per second)\n",
            "llama_print_timings:       total time =   14938.69 ms /   739 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     568.46 ms /   256 runs   (    2.22 ms per token,   450.34 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1148.86 ms /   954 tokens (    1.20 ms per token,   830.39 tokens per second)\n",
            "llama_print_timings:        eval time =   13538.88 ms /   255 runs   (   53.09 ms per token,    18.83 tokens per second)\n",
            "llama_print_timings:       total time =   15560.14 ms /  1209 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     586.20 ms /   256 runs   (    2.29 ms per token,   436.71 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1173.00 ms /   994 tokens (    1.18 ms per token,   847.40 tokens per second)\n",
            "llama_print_timings:        eval time =   13558.09 ms /   255 runs   (   53.17 ms per token,    18.81 tokens per second)\n",
            "llama_print_timings:       total time =   15609.07 ms /  1249 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     566.79 ms /   256 runs   (    2.21 ms per token,   451.66 tokens per second)\n",
            "llama_print_timings: prompt eval time =     239.92 ms /   118 tokens (    2.03 ms per token,   491.82 tokens per second)\n",
            "llama_print_timings:        eval time =   13598.60 ms /   255 runs   (   53.33 ms per token,    18.75 tokens per second)\n",
            "llama_print_timings:       total time =   14689.01 ms /   373 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     607.69 ms /   256 runs   (    2.37 ms per token,   421.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1097.15 ms /   894 tokens (    1.23 ms per token,   814.84 tokens per second)\n",
            "llama_print_timings:        eval time =   13414.27 ms /   255 runs   (   52.60 ms per token,    19.01 tokens per second)\n",
            "llama_print_timings:       total time =   15427.27 ms /  1149 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     560.83 ms /   256 runs   (    2.19 ms per token,   456.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1158.64 ms /   935 tokens (    1.24 ms per token,   806.98 tokens per second)\n",
            "llama_print_timings:        eval time =   13525.52 ms /   255 runs   (   53.04 ms per token,    18.85 tokens per second)\n",
            "llama_print_timings:       total time =   15546.32 ms /  1190 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     571.38 ms /   256 runs   (    2.23 ms per token,   448.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1800.71 ms /  1433 tokens (    1.26 ms per token,   795.80 tokens per second)\n",
            "llama_print_timings:        eval time =   13544.71 ms /   255 runs   (   53.12 ms per token,    18.83 tokens per second)\n",
            "llama_print_timings:       total time =   16325.51 ms /  1688 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     558.20 ms /   256 runs   (    2.18 ms per token,   458.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1690.42 ms /  1287 tokens (    1.31 ms per token,   761.35 tokens per second)\n",
            "llama_print_timings:        eval time =   13666.51 ms /   255 runs   (   53.59 ms per token,    18.66 tokens per second)\n",
            "llama_print_timings:       total time =   16225.07 ms /  1542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     583.47 ms /   256 runs   (    2.28 ms per token,   438.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1708.83 ms /  1370 tokens (    1.25 ms per token,   801.72 tokens per second)\n",
            "llama_print_timings:        eval time =   13738.94 ms /   255 runs   (   53.88 ms per token,    18.56 tokens per second)\n",
            "llama_print_timings:       total time =   16323.99 ms /  1625 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     553.89 ms /   256 runs   (    2.16 ms per token,   462.19 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1580.08 ms /  1219 tokens (    1.30 ms per token,   771.48 tokens per second)\n",
            "llama_print_timings:        eval time =   13707.55 ms /   255 runs   (   53.76 ms per token,    18.60 tokens per second)\n",
            "llama_print_timings:       total time =   16139.19 ms /  1474 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     547.83 ms /   256 runs   (    2.14 ms per token,   467.29 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1717.16 ms /  1356 tokens (    1.27 ms per token,   789.67 tokens per second)\n",
            "llama_print_timings:        eval time =   13938.87 ms /   255 runs   (   54.66 ms per token,    18.29 tokens per second)\n",
            "llama_print_timings:       total time =   16494.47 ms /  1611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     540.62 ms /   256 runs   (    2.11 ms per token,   473.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1578.32 ms /  1208 tokens (    1.31 ms per token,   765.37 tokens per second)\n",
            "llama_print_timings:        eval time =   13849.99 ms /   255 runs   (   54.31 ms per token,    18.41 tokens per second)\n",
            "llama_print_timings:       total time =   16260.88 ms /  1463 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     571.27 ms /   256 runs   (    2.23 ms per token,   448.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1733.26 ms /  1356 tokens (    1.28 ms per token,   782.34 tokens per second)\n",
            "llama_print_timings:        eval time =   13692.49 ms /   255 runs   (   53.70 ms per token,    18.62 tokens per second)\n",
            "llama_print_timings:       total time =   16305.77 ms /  1611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     567.67 ms /   256 runs   (    2.22 ms per token,   450.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1583.27 ms /  1207 tokens (    1.31 ms per token,   762.35 tokens per second)\n",
            "llama_print_timings:        eval time =   13711.14 ms /   255 runs   (   53.77 ms per token,    18.60 tokens per second)\n",
            "llama_print_timings:       total time =   16168.60 ms /  1462 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     555.20 ms /   256 runs   (    2.17 ms per token,   461.09 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1839.90 ms /  1431 tokens (    1.29 ms per token,   777.76 tokens per second)\n",
            "llama_print_timings:        eval time =   13863.62 ms /   255 runs   (   54.37 ms per token,    18.39 tokens per second)\n",
            "llama_print_timings:       total time =   16546.87 ms /  1686 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     546.46 ms /   256 runs   (    2.13 ms per token,   468.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1603.68 ms /  1279 tokens (    1.25 ms per token,   797.54 tokens per second)\n",
            "llama_print_timings:        eval time =   13768.59 ms /   255 runs   (   53.99 ms per token,    18.52 tokens per second)\n",
            "llama_print_timings:       total time =   16193.32 ms /  1534 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     558.65 ms /   256 runs   (    2.18 ms per token,   458.25 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1732.41 ms /  1356 tokens (    1.28 ms per token,   782.72 tokens per second)\n",
            "llama_print_timings:        eval time =   13586.97 ms /   255 runs   (   53.28 ms per token,    18.77 tokens per second)\n",
            "llama_print_timings:       total time =   16169.72 ms /  1611 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     558.66 ms /   256 runs   (    2.18 ms per token,   458.24 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1575.92 ms /  1206 tokens (    1.31 ms per token,   765.27 tokens per second)\n",
            "llama_print_timings:        eval time =   13695.37 ms /   255 runs   (   53.71 ms per token,    18.62 tokens per second)\n",
            "llama_print_timings:       total time =   16121.05 ms /  1461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     555.26 ms /   256 runs   (    2.17 ms per token,   461.04 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1720.31 ms /  1388 tokens (    1.24 ms per token,   806.83 tokens per second)\n",
            "llama_print_timings:        eval time =   13682.10 ms /   255 runs   (   53.66 ms per token,    18.64 tokens per second)\n",
            "llama_print_timings:       total time =   16251.75 ms /  1643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     575.22 ms /   256 runs   (    2.25 ms per token,   445.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1593.94 ms /  1252 tokens (    1.27 ms per token,   785.47 tokens per second)\n",
            "llama_print_timings:        eval time =   13671.85 ms /   255 runs   (   53.62 ms per token,    18.65 tokens per second)\n",
            "llama_print_timings:       total time =   16143.85 ms /  1507 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     584.60 ms /   256 runs   (    2.28 ms per token,   437.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1752.92 ms /  1388 tokens (    1.26 ms per token,   791.82 tokens per second)\n",
            "llama_print_timings:        eval time =   13705.58 ms /   255 runs   (   53.75 ms per token,    18.61 tokens per second)\n",
            "llama_print_timings:       total time =   16375.14 ms /  1643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     558.32 ms /   256 runs   (    2.18 ms per token,   458.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1618.97 ms /  1272 tokens (    1.27 ms per token,   785.69 tokens per second)\n",
            "llama_print_timings:        eval time =   13602.33 ms /   255 runs   (   53.34 ms per token,    18.75 tokens per second)\n",
            "llama_print_timings:       total time =   16108.79 ms /  1527 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     596.08 ms /   256 runs   (    2.33 ms per token,   429.47 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1742.01 ms /  1391 tokens (    1.25 ms per token,   798.50 tokens per second)\n",
            "llama_print_timings:        eval time =   13553.15 ms /   255 runs   (   53.15 ms per token,    18.81 tokens per second)\n",
            "llama_print_timings:       total time =   16263.80 ms /  1646 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     597.10 ms /   256 runs   (    2.33 ms per token,   428.74 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1584.25 ms /  1239 tokens (    1.28 ms per token,   782.07 tokens per second)\n",
            "llama_print_timings:        eval time =   13661.37 ms /   255 runs   (   53.57 ms per token,    18.67 tokens per second)\n",
            "llama_print_timings:       total time =   16144.31 ms /  1494 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     575.98 ms /   256 runs   (    2.25 ms per token,   444.46 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1737.03 ms /  1392 tokens (    1.25 ms per token,   801.37 tokens per second)\n",
            "llama_print_timings:        eval time =   13753.83 ms /   255 runs   (   53.94 ms per token,    18.54 tokens per second)\n",
            "llama_print_timings:       total time =   16384.86 ms /  1647 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     567.40 ms /   256 runs   (    2.22 ms per token,   451.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1596.61 ms /  1267 tokens (    1.26 ms per token,   793.55 tokens per second)\n",
            "llama_print_timings:        eval time =   13687.44 ms /   255 runs   (   53.68 ms per token,    18.63 tokens per second)\n",
            "llama_print_timings:       total time =   16172.27 ms /  1522 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     588.10 ms /   256 runs   (    2.30 ms per token,   435.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1806.29 ms /  1411 tokens (    1.28 ms per token,   781.16 tokens per second)\n",
            "llama_print_timings:        eval time =   13663.67 ms /   255 runs   (   53.58 ms per token,    18.66 tokens per second)\n",
            "llama_print_timings:       total time =   16368.07 ms /  1666 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     567.46 ms /   256 runs   (    2.22 ms per token,   451.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1586.18 ms /  1273 tokens (    1.25 ms per token,   802.56 tokens per second)\n",
            "llama_print_timings:        eval time =   13708.14 ms /   255 runs   (   53.76 ms per token,    18.60 tokens per second)\n",
            "llama_print_timings:       total time =   16150.69 ms /  1528 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     607.88 ms /   256 runs   (    2.37 ms per token,   421.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1738.06 ms /  1403 tokens (    1.24 ms per token,   807.22 tokens per second)\n",
            "llama_print_timings:        eval time =   13741.33 ms /   255 runs   (   53.89 ms per token,    18.56 tokens per second)\n",
            "llama_print_timings:       total time =   16398.48 ms /  1658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     588.32 ms /   256 runs   (    2.30 ms per token,   435.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1708.39 ms /  1322 tokens (    1.29 ms per token,   773.83 tokens per second)\n",
            "llama_print_timings:        eval time =   13681.89 ms /   255 runs   (   53.65 ms per token,    18.64 tokens per second)\n",
            "llama_print_timings:       total time =   16304.94 ms /  1577 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     586.47 ms /   256 runs   (    2.29 ms per token,   436.51 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1794.60 ms /  1422 tokens (    1.26 ms per token,   792.38 tokens per second)\n",
            "llama_print_timings:        eval time =   13648.55 ms /   255 runs   (   53.52 ms per token,    18.68 tokens per second)\n",
            "llama_print_timings:       total time =   16353.74 ms /  1677 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     583.26 ms /   256 runs   (    2.28 ms per token,   438.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1603.06 ms /  1276 tokens (    1.26 ms per token,   795.98 tokens per second)\n",
            "llama_print_timings:        eval time =   13577.10 ms /   255 runs   (   53.24 ms per token,    18.78 tokens per second)\n",
            "llama_print_timings:       total time =   16082.72 ms /  1531 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     581.90 ms /   256 runs   (    2.27 ms per token,   439.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1774.99 ms /  1416 tokens (    1.25 ms per token,   797.75 tokens per second)\n",
            "llama_print_timings:        eval time =   13578.73 ms /   255 runs   (   53.25 ms per token,    18.78 tokens per second)\n",
            "llama_print_timings:       total time =   16240.53 ms /  1671 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     593.12 ms /   256 runs   (    2.32 ms per token,   431.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1712.77 ms /  1340 tokens (    1.28 ms per token,   782.36 tokens per second)\n",
            "llama_print_timings:        eval time =   13635.72 ms /   255 runs   (   53.47 ms per token,    18.70 tokens per second)\n",
            "llama_print_timings:       total time =   16262.65 ms /  1595 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     572.15 ms /   256 runs   (    2.23 ms per token,   447.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1744.09 ms /  1402 tokens (    1.24 ms per token,   803.86 tokens per second)\n",
            "llama_print_timings:        eval time =   13612.76 ms /   255 runs   (   53.38 ms per token,    18.73 tokens per second)\n",
            "llama_print_timings:       total time =   16266.23 ms /  1657 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     563.82 ms /   256 runs   (    2.20 ms per token,   454.05 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1586.11 ms /  1249 tokens (    1.27 ms per token,   787.46 tokens per second)\n",
            "llama_print_timings:        eval time =   13552.69 ms /   255 runs   (   53.15 ms per token,    18.82 tokens per second)\n",
            "llama_print_timings:       total time =   16060.20 ms /  1504 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     590.20 ms /   256 runs   (    2.31 ms per token,   433.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1796.72 ms /  1410 tokens (    1.27 ms per token,   784.76 tokens per second)\n",
            "llama_print_timings:        eval time =   13476.19 ms /   255 runs   (   52.85 ms per token,    18.92 tokens per second)\n",
            "llama_print_timings:       total time =   16271.67 ms /  1665 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     608.59 ms /   256 runs   (    2.38 ms per token,   420.65 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1694.58 ms /  1310 tokens (    1.29 ms per token,   773.05 tokens per second)\n",
            "llama_print_timings:        eval time =   13587.07 ms /   255 runs   (   53.28 ms per token,    18.77 tokens per second)\n",
            "llama_print_timings:       total time =   16279.83 ms /  1565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     577.64 ms /   256 runs   (    2.26 ms per token,   443.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1778.29 ms /  1426 tokens (    1.25 ms per token,   801.89 tokens per second)\n",
            "llama_print_timings:        eval time =   13656.08 ms /   255 runs   (   53.55 ms per token,    18.67 tokens per second)\n",
            "llama_print_timings:       total time =   16403.31 ms /  1681 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     589.82 ms /   256 runs   (    2.30 ms per token,   434.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1663.14 ms /  1282 tokens (    1.30 ms per token,   770.83 tokens per second)\n",
            "llama_print_timings:        eval time =   13558.66 ms /   255 runs   (   53.17 ms per token,    18.81 tokens per second)\n",
            "llama_print_timings:       total time =   16166.25 ms /  1537 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     581.09 ms /   256 runs   (    2.27 ms per token,   440.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1746.49 ms /  1397 tokens (    1.25 ms per token,   799.89 tokens per second)\n",
            "llama_print_timings:        eval time =   13537.41 ms /   255 runs   (   53.09 ms per token,    18.84 tokens per second)\n",
            "llama_print_timings:       total time =   16216.65 ms /  1652 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     600.14 ms /   256 runs   (    2.34 ms per token,   426.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1665.11 ms /  1284 tokens (    1.30 ms per token,   771.12 tokens per second)\n",
            "llama_print_timings:        eval time =   13408.46 ms /   255 runs   (   52.58 ms per token,    19.02 tokens per second)\n",
            "llama_print_timings:       total time =   16045.55 ms /  1539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     584.59 ms /   256 runs   (    2.28 ms per token,   437.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1839.53 ms /  1444 tokens (    1.27 ms per token,   784.98 tokens per second)\n",
            "llama_print_timings:        eval time =   13520.04 ms /   255 runs   (   53.02 ms per token,    18.86 tokens per second)\n",
            "llama_print_timings:       total time =   16328.67 ms /  1699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     575.96 ms /   256 runs   (    2.25 ms per token,   444.48 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1657.65 ms /  1288 tokens (    1.29 ms per token,   777.00 tokens per second)\n",
            "llama_print_timings:        eval time =   13561.83 ms /   255 runs   (   53.18 ms per token,    18.80 tokens per second)\n",
            "llama_print_timings:       total time =   16159.56 ms /  1543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     578.47 ms /   256 runs   (    2.26 ms per token,   442.55 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1705.82 ms /  1377 tokens (    1.24 ms per token,   807.23 tokens per second)\n",
            "llama_print_timings:        eval time =   13615.35 ms /   255 runs   (   53.39 ms per token,    18.73 tokens per second)\n",
            "llama_print_timings:       total time =   16229.78 ms /  1632 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     599.00 ms /   256 runs   (    2.34 ms per token,   427.38 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1677.36 ms /  1288 tokens (    1.30 ms per token,   767.87 tokens per second)\n",
            "llama_print_timings:        eval time =   13528.54 ms /   255 runs   (   53.05 ms per token,    18.85 tokens per second)\n",
            "llama_print_timings:       total time =   16179.96 ms /  1543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     566.28 ms /   256 runs   (    2.21 ms per token,   452.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1782.40 ms /  1450 tokens (    1.23 ms per token,   813.51 tokens per second)\n",
            "llama_print_timings:        eval time =   13561.62 ms /   255 runs   (   53.18 ms per token,    18.80 tokens per second)\n",
            "llama_print_timings:       total time =   16223.43 ms /  1705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     588.53 ms /   256 runs   (    2.30 ms per token,   434.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1673.43 ms /  1294 tokens (    1.29 ms per token,   773.26 tokens per second)\n",
            "llama_print_timings:        eval time =   13641.31 ms /   255 runs   (   53.50 ms per token,    18.69 tokens per second)\n",
            "llama_print_timings:       total time =   16203.30 ms /  1549 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     580.28 ms /   256 runs   (    2.27 ms per token,   441.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1844.62 ms /  1451 tokens (    1.27 ms per token,   786.61 tokens per second)\n",
            "llama_print_timings:        eval time =   13728.02 ms /   255 runs   (   53.84 ms per token,    18.58 tokens per second)\n",
            "llama_print_timings:       total time =   16461.58 ms /  1706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     537.74 ms /   256 runs   (    2.10 ms per token,   476.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1867.15 ms /  1518 tokens (    1.23 ms per token,   813.01 tokens per second)\n",
            "llama_print_timings:        eval time =   13633.80 ms /   255 runs   (   53.47 ms per token,    18.70 tokens per second)\n",
            "llama_print_timings:       total time =   16417.19 ms /  1773 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     570.33 ms /   256 runs   (    2.23 ms per token,   448.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1847.23 ms /  1450 tokens (    1.27 ms per token,   784.96 tokens per second)\n",
            "llama_print_timings:        eval time =   13637.98 ms /   255 runs   (   53.48 ms per token,    18.70 tokens per second)\n",
            "llama_print_timings:       total time =   16371.26 ms /  1705 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     580.82 ms /   256 runs   (    2.27 ms per token,   440.76 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1697.94 ms /  1288 tokens (    1.32 ms per token,   758.57 tokens per second)\n",
            "llama_print_timings:        eval time =   13871.15 ms /   255 runs   (   54.40 ms per token,    18.38 tokens per second)\n",
            "llama_print_timings:       total time =   16449.66 ms /  1543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     582.48 ms /   256 runs   (    2.28 ms per token,   439.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1837.21 ms /  1451 tokens (    1.27 ms per token,   789.79 tokens per second)\n",
            "llama_print_timings:        eval time =   13805.42 ms /   255 runs   (   54.14 ms per token,    18.47 tokens per second)\n",
            "llama_print_timings:       total time =   16538.62 ms /  1706 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     518.32 ms /   256 runs   (    2.02 ms per token,   493.91 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1866.91 ms /  1524 tokens (    1.23 ms per token,   816.32 tokens per second)\n",
            "llama_print_timings:        eval time =   13864.98 ms /   255 runs   (   54.37 ms per token,    18.39 tokens per second)\n",
            "llama_print_timings:       total time =   16590.79 ms /  1779 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     586.32 ms /   256 runs   (    2.29 ms per token,   436.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1745.02 ms /  1403 tokens (    1.24 ms per token,   804.00 tokens per second)\n",
            "llama_print_timings:        eval time =   13773.74 ms /   255 runs   (   54.01 ms per token,    18.51 tokens per second)\n",
            "llama_print_timings:       total time =   16419.31 ms /  1658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     580.70 ms /   256 runs   (    2.27 ms per token,   440.85 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1599.57 ms /  1258 tokens (    1.27 ms per token,   786.46 tokens per second)\n",
            "llama_print_timings:        eval time =   13768.74 ms /   255 runs   (   54.00 ms per token,    18.52 tokens per second)\n",
            "llama_print_timings:       total time =   16260.68 ms /  1513 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     579.10 ms /   256 runs   (    2.26 ms per token,   442.07 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1723.51 ms /  1335 tokens (    1.29 ms per token,   774.58 tokens per second)\n",
            "llama_print_timings:        eval time =   13663.40 ms /   255 runs   (   53.58 ms per token,    18.66 tokens per second)\n",
            "llama_print_timings:       total time =   16325.87 ms /  1590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     578.29 ms /   256 runs   (    2.26 ms per token,   442.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1577.02 ms /  1214 tokens (    1.30 ms per token,   769.81 tokens per second)\n",
            "llama_print_timings:        eval time =   13532.73 ms /   255 runs   (   53.07 ms per token,    18.84 tokens per second)\n",
            "llama_print_timings:       total time =   16054.41 ms /  1469 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     591.29 ms /   256 runs   (    2.31 ms per token,   432.95 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1721.45 ms /  1335 tokens (    1.29 ms per token,   775.51 tokens per second)\n",
            "llama_print_timings:        eval time =   13606.65 ms /   255 runs   (   53.36 ms per token,    18.74 tokens per second)\n",
            "llama_print_timings:       total time =   16288.95 ms /  1590 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     582.43 ms /   256 runs   (    2.28 ms per token,   439.54 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1572.88 ms /  1182 tokens (    1.33 ms per token,   751.49 tokens per second)\n",
            "llama_print_timings:        eval time =   13553.02 ms /   255 runs   (   53.15 ms per token,    18.82 tokens per second)\n",
            "llama_print_timings:       total time =   16046.61 ms /  1437 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     577.07 ms /   256 runs   (    2.25 ms per token,   443.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1673.84 ms /  1303 tokens (    1.28 ms per token,   778.45 tokens per second)\n",
            "llama_print_timings:        eval time =   13524.55 ms /   255 runs   (   53.04 ms per token,    18.85 tokens per second)\n",
            "llama_print_timings:       total time =   16120.85 ms /  1558 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     565.91 ms /   256 runs   (    2.21 ms per token,   452.37 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1465.34 ms /  1141 tokens (    1.28 ms per token,   778.66 tokens per second)\n",
            "llama_print_timings:        eval time =   13497.44 ms /   255 runs   (   52.93 ms per token,    18.89 tokens per second)\n",
            "llama_print_timings:       total time =   15870.83 ms /  1396 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     596.84 ms /   256 runs   (    2.33 ms per token,   428.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1726.44 ms /  1378 tokens (    1.25 ms per token,   798.17 tokens per second)\n",
            "llama_print_timings:        eval time =   13621.79 ms /   255 runs   (   53.42 ms per token,    18.72 tokens per second)\n",
            "llama_print_timings:       total time =   16281.65 ms /  1633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     563.61 ms /   256 runs   (    2.20 ms per token,   454.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1555.25 ms /  1226 tokens (    1.27 ms per token,   788.30 tokens per second)\n",
            "llama_print_timings:        eval time =   13567.00 ms /   255 runs   (   53.20 ms per token,    18.80 tokens per second)\n",
            "llama_print_timings:       total time =   16004.47 ms /  1481 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     572.68 ms /   256 runs   (    2.24 ms per token,   447.02 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1716.47 ms /  1379 tokens (    1.24 ms per token,   803.39 tokens per second)\n",
            "llama_print_timings:        eval time =   13500.25 ms /   255 runs   (   52.94 ms per token,    18.89 tokens per second)\n",
            "llama_print_timings:       total time =   16107.46 ms /  1634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     591.00 ms /   256 runs   (    2.31 ms per token,   433.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1579.67 ms /  1234 tokens (    1.28 ms per token,   781.18 tokens per second)\n",
            "llama_print_timings:        eval time =   13581.92 ms /   255 runs   (   53.26 ms per token,    18.77 tokens per second)\n",
            "llama_print_timings:       total time =   16082.28 ms /  1489 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     564.47 ms /   256 runs   (    2.20 ms per token,   453.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1721.98 ms /  1361 tokens (    1.27 ms per token,   790.37 tokens per second)\n",
            "llama_print_timings:        eval time =   13606.88 ms /   255 runs   (   53.36 ms per token,    18.74 tokens per second)\n",
            "llama_print_timings:       total time =   16194.26 ms /  1616 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     564.46 ms /   256 runs   (    2.20 ms per token,   453.53 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1554.00 ms /  1201 tokens (    1.29 ms per token,   772.84 tokens per second)\n",
            "llama_print_timings:        eval time =   13681.76 ms /   255 runs   (   53.65 ms per token,    18.64 tokens per second)\n",
            "llama_print_timings:       total time =   16107.23 ms /  1456 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     583.57 ms /   256 runs   (    2.28 ms per token,   438.68 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1717.44 ms /  1361 tokens (    1.26 ms per token,   792.46 tokens per second)\n",
            "llama_print_timings:        eval time =   13548.18 ms /   255 runs   (   53.13 ms per token,    18.82 tokens per second)\n",
            "llama_print_timings:       total time =   16152.39 ms /  1616 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     562.94 ms /   256 runs   (    2.20 ms per token,   454.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1581.92 ms /  1203 tokens (    1.31 ms per token,   760.47 tokens per second)\n",
            "llama_print_timings:        eval time =   13529.84 ms /   255 runs   (   53.06 ms per token,    18.85 tokens per second)\n",
            "llama_print_timings:       total time =   15982.66 ms /  1458 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     567.97 ms /   256 runs   (    2.22 ms per token,   450.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1834.40 ms /  1448 tokens (    1.27 ms per token,   789.36 tokens per second)\n",
            "llama_print_timings:        eval time =   13687.81 ms /   255 runs   (   53.68 ms per token,    18.63 tokens per second)\n",
            "llama_print_timings:       total time =   16416.41 ms /  1703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     569.15 ms /   256 runs   (    2.22 ms per token,   449.80 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1690.05 ms /  1295 tokens (    1.31 ms per token,   766.25 tokens per second)\n",
            "llama_print_timings:        eval time =   13744.20 ms /   255 runs   (   53.90 ms per token,    18.55 tokens per second)\n",
            "llama_print_timings:       total time =   16325.90 ms /  1550 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     589.19 ms /   256 runs   (    2.30 ms per token,   434.50 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1836.38 ms /  1448 tokens (    1.27 ms per token,   788.51 tokens per second)\n",
            "llama_print_timings:        eval time =   13727.19 ms /   255 runs   (   53.83 ms per token,    18.58 tokens per second)\n",
            "llama_print_timings:       total time =   16500.33 ms /  1703 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     557.24 ms /   256 runs   (    2.18 ms per token,   459.40 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1686.39 ms /  1286 tokens (    1.31 ms per token,   762.57 tokens per second)\n",
            "llama_print_timings:        eval time =   13689.18 ms /   255 runs   (   53.68 ms per token,    18.63 tokens per second)\n",
            "llama_print_timings:       total time =   16277.86 ms /  1541 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     566.38 ms /   256 runs   (    2.21 ms per token,   451.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1834.90 ms /  1452 tokens (    1.26 ms per token,   791.33 tokens per second)\n",
            "llama_print_timings:        eval time =   13681.84 ms /   255 runs   (   53.65 ms per token,    18.64 tokens per second)\n",
            "llama_print_timings:       total time =   16418.56 ms /  1707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     561.99 ms /   256 runs   (    2.20 ms per token,   455.52 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1685.44 ms /  1288 tokens (    1.31 ms per token,   764.19 tokens per second)\n",
            "llama_print_timings:        eval time =   13763.98 ms /   255 runs   (   53.98 ms per token,    18.53 tokens per second)\n",
            "llama_print_timings:       total time =   16326.36 ms /  1543 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     597.13 ms /   256 runs   (    2.33 ms per token,   428.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1857.85 ms /  1452 tokens (    1.28 ms per token,   781.55 tokens per second)\n",
            "llama_print_timings:        eval time =   13734.05 ms /   255 runs   (   53.86 ms per token,    18.57 tokens per second)\n",
            "llama_print_timings:       total time =   16513.33 ms /  1707 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     575.10 ms /   256 runs   (    2.25 ms per token,   445.14 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1771.63 ms /  1399 tokens (    1.27 ms per token,   789.67 tokens per second)\n",
            "llama_print_timings:        eval time =   13698.70 ms /   255 runs   (   53.72 ms per token,    18.61 tokens per second)\n",
            "llama_print_timings:       total time =   16389.68 ms /  1654 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     568.51 ms /   256 runs   (    2.22 ms per token,   450.30 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1834.95 ms /  1424 tokens (    1.29 ms per token,   776.04 tokens per second)\n",
            "llama_print_timings:        eval time =   13796.48 ms /   255 runs   (   54.10 ms per token,    18.48 tokens per second)\n",
            "llama_print_timings:       total time =   16520.46 ms /  1679 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     569.59 ms /   256 runs   (    2.22 ms per token,   449.44 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1602.39 ms /  1270 tokens (    1.26 ms per token,   792.57 tokens per second)\n",
            "llama_print_timings:        eval time =   13638.45 ms /   255 runs   (   53.48 ms per token,    18.70 tokens per second)\n",
            "llama_print_timings:       total time =   16126.82 ms /  1525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     611.47 ms /   256 runs   (    2.39 ms per token,   418.67 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1811.43 ms /  1431 tokens (    1.27 ms per token,   789.98 tokens per second)\n",
            "llama_print_timings:        eval time =   13510.44 ms /   255 runs   (   52.98 ms per token,    18.87 tokens per second)\n",
            "llama_print_timings:       total time =   16283.88 ms /  1686 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     589.96 ms /   256 runs   (    2.30 ms per token,   433.93 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1605.77 ms /  1266 tokens (    1.27 ms per token,   788.40 tokens per second)\n",
            "llama_print_timings:        eval time =   13649.44 ms /   255 runs   (   53.53 ms per token,    18.68 tokens per second)\n",
            "llama_print_timings:       total time =   16149.79 ms /  1521 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     583.69 ms /   256 runs   (    2.28 ms per token,   438.59 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1819.35 ms /  1464 tokens (    1.24 ms per token,   804.68 tokens per second)\n",
            "llama_print_timings:        eval time =   13492.01 ms /   255 runs   (   52.91 ms per token,    18.90 tokens per second)\n",
            "llama_print_timings:       total time =   16226.76 ms /  1719 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     577.84 ms /   256 runs   (    2.26 ms per token,   443.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1682.26 ms /  1310 tokens (    1.28 ms per token,   778.71 tokens per second)\n",
            "llama_print_timings:        eval time =   13627.84 ms /   255 runs   (   53.44 ms per token,    18.71 tokens per second)\n",
            "llama_print_timings:       total time =   16196.40 ms /  1565 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     624.60 ms /   256 runs   (    2.44 ms per token,   409.86 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1819.68 ms /  1439 tokens (    1.26 ms per token,   790.80 tokens per second)\n",
            "llama_print_timings:        eval time =   13516.86 ms /   255 runs   (   53.01 ms per token,    18.87 tokens per second)\n",
            "llama_print_timings:       total time =   16324.91 ms /  1694 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     622.34 ms /   256 runs   (    2.43 ms per token,   411.35 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1665.71 ms /  1317 tokens (    1.26 ms per token,   790.65 tokens per second)\n",
            "llama_print_timings:        eval time =   13490.77 ms /   255 runs   (   52.90 ms per token,    18.90 tokens per second)\n",
            "llama_print_timings:       total time =   16129.00 ms /  1572 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     627.15 ms /   256 runs   (    2.45 ms per token,   408.20 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1707.39 ms /  1357 tokens (    1.26 ms per token,   794.78 tokens per second)\n",
            "llama_print_timings:        eval time =   13556.18 ms /   255 runs   (   53.16 ms per token,    18.81 tokens per second)\n",
            "llama_print_timings:       total time =   16247.96 ms /  1612 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     634.24 ms /   256 runs   (    2.48 ms per token,   403.64 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1571.59 ms /  1205 tokens (    1.30 ms per token,   766.74 tokens per second)\n",
            "llama_print_timings:        eval time =   13472.83 ms /   255 runs   (   52.83 ms per token,    18.93 tokens per second)\n",
            "llama_print_timings:       total time =   16053.47 ms /  1460 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     623.73 ms /   256 runs   (    2.44 ms per token,   410.43 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1718.06 ms /  1357 tokens (    1.27 ms per token,   789.84 tokens per second)\n",
            "llama_print_timings:        eval time =   13643.55 ms /   255 runs   (   53.50 ms per token,    18.69 tokens per second)\n",
            "llama_print_timings:       total time =   16361.37 ms /  1612 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     609.23 ms /   256 runs   (    2.38 ms per token,   420.21 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1558.68 ms /  1215 tokens (    1.28 ms per token,   779.50 tokens per second)\n",
            "llama_print_timings:        eval time =   13623.72 ms /   255 runs   (   53.43 ms per token,    18.72 tokens per second)\n",
            "llama_print_timings:       total time =   16144.50 ms /  1470 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     609.49 ms /   256 runs   (    2.38 ms per token,   420.03 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1729.00 ms /  1371 tokens (    1.26 ms per token,   792.94 tokens per second)\n",
            "llama_print_timings:        eval time =   13549.73 ms /   255 runs   (   53.14 ms per token,    18.82 tokens per second)\n",
            "llama_print_timings:       total time =   16271.73 ms /  1626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     603.79 ms /   256 runs   (    2.36 ms per token,   423.99 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1590.82 ms /  1210 tokens (    1.31 ms per token,   760.61 tokens per second)\n",
            "llama_print_timings:        eval time =   13643.57 ms /   255 runs   (   53.50 ms per token,    18.69 tokens per second)\n",
            "llama_print_timings:       total time =   16179.29 ms /  1465 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     609.30 ms /   256 runs   (    2.38 ms per token,   420.16 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1746.38 ms /  1371 tokens (    1.27 ms per token,   785.05 tokens per second)\n",
            "llama_print_timings:        eval time =   13694.63 ms /   255 runs   (   53.70 ms per token,    18.62 tokens per second)\n",
            "llama_print_timings:       total time =   16390.36 ms /  1626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     591.31 ms /   256 runs   (    2.31 ms per token,   432.94 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1568.87 ms /  1206 tokens (    1.30 ms per token,   768.71 tokens per second)\n",
            "llama_print_timings:        eval time =   13606.15 ms /   255 runs   (   53.36 ms per token,    18.74 tokens per second)\n",
            "llama_print_timings:       total time =   16124.19 ms /  1461 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     576.28 ms /   256 runs   (    2.25 ms per token,   444.23 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1847.40 ms /  1433 tokens (    1.29 ms per token,   775.68 tokens per second)\n",
            "llama_print_timings:        eval time =   13711.63 ms /   255 runs   (   53.77 ms per token,    18.60 tokens per second)\n",
            "llama_print_timings:       total time =   16476.13 ms /  1688 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     565.05 ms /   256 runs   (    2.21 ms per token,   453.06 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1618.20 ms /  1270 tokens (    1.27 ms per token,   784.82 tokens per second)\n",
            "llama_print_timings:        eval time =   13784.53 ms /   255 runs   (   54.06 ms per token,    18.50 tokens per second)\n",
            "llama_print_timings:       total time =   16302.28 ms /  1525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     579.21 ms /   256 runs   (    2.26 ms per token,   441.98 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1837.78 ms /  1432 tokens (    1.28 ms per token,   779.20 tokens per second)\n",
            "llama_print_timings:        eval time =   13734.02 ms /   255 runs   (   53.86 ms per token,    18.57 tokens per second)\n",
            "llama_print_timings:       total time =   16497.48 ms /  1687 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     339.63 ms /   157 runs   (    2.16 ms per token,   462.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1601.14 ms /  1278 tokens (    1.25 ms per token,   798.18 tokens per second)\n",
            "llama_print_timings:        eval time =    8339.79 ms /   156 runs   (   53.46 ms per token,    18.71 tokens per second)\n",
            "llama_print_timings:       total time =   10463.46 ms /  1434 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     568.13 ms /   256 runs   (    2.22 ms per token,   450.60 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1802.68 ms /  1427 tokens (    1.26 ms per token,   791.60 tokens per second)\n",
            "llama_print_timings:        eval time =   13576.79 ms /   255 runs   (   53.24 ms per token,    18.78 tokens per second)\n",
            "llama_print_timings:       total time =   16317.87 ms /  1682 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     581.17 ms /   256 runs   (    2.27 ms per token,   440.49 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1604.52 ms /  1270 tokens (    1.26 ms per token,   791.52 tokens per second)\n",
            "llama_print_timings:        eval time =   13492.46 ms /   255 runs   (   52.91 ms per token,    18.90 tokens per second)\n",
            "llama_print_timings:       total time =   16073.28 ms /  1525 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     588.91 ms /   256 runs   (    2.30 ms per token,   434.70 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1831.21 ms /  1440 tokens (    1.27 ms per token,   786.37 tokens per second)\n",
            "llama_print_timings:        eval time =   13534.93 ms /   255 runs   (   53.08 ms per token,    18.84 tokens per second)\n",
            "llama_print_timings:       total time =   16340.57 ms /  1695 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     586.19 ms /   256 runs   (    2.29 ms per token,   436.72 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1655.57 ms /  1287 tokens (    1.29 ms per token,   777.37 tokens per second)\n",
            "llama_print_timings:        eval time =   13573.49 ms /   255 runs   (   53.23 ms per token,    18.79 tokens per second)\n",
            "llama_print_timings:       total time =   16163.57 ms /  1542 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     602.68 ms /   256 runs   (    2.35 ms per token,   424.77 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1713.01 ms /  1379 tokens (    1.24 ms per token,   805.02 tokens per second)\n",
            "llama_print_timings:        eval time =   13566.99 ms /   255 runs   (   53.20 ms per token,    18.80 tokens per second)\n",
            "llama_print_timings:       total time =   16227.40 ms /  1634 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     598.73 ms /   256 runs   (    2.34 ms per token,   427.57 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1588.67 ms /  1225 tokens (    1.30 ms per token,   771.09 tokens per second)\n",
            "llama_print_timings:        eval time =   13554.60 ms /   255 runs   (   53.16 ms per token,    18.81 tokens per second)\n",
            "llama_print_timings:       total time =   16086.94 ms /  1480 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     589.49 ms /   256 runs   (    2.30 ms per token,   434.27 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1711.19 ms /  1378 tokens (    1.24 ms per token,   805.29 tokens per second)\n",
            "llama_print_timings:        eval time =   13628.76 ms /   255 runs   (   53.45 ms per token,    18.71 tokens per second)\n",
            "llama_print_timings:       total time =   16259.94 ms /  1633 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     598.67 ms /   256 runs   (    2.34 ms per token,   427.62 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1564.20 ms /  1223 tokens (    1.28 ms per token,   781.87 tokens per second)\n",
            "llama_print_timings:        eval time =   13600.51 ms /   255 runs   (   53.34 ms per token,    18.75 tokens per second)\n",
            "llama_print_timings:       total time =   16095.75 ms /  1478 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     581.40 ms /   256 runs   (    2.27 ms per token,   440.32 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1721.84 ms /  1371 tokens (    1.26 ms per token,   796.24 tokens per second)\n",
            "llama_print_timings:        eval time =   13534.66 ms /   255 runs   (   53.08 ms per token,    18.84 tokens per second)\n",
            "llama_print_timings:       total time =   16197.92 ms /  1626 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     590.98 ms /   256 runs   (    2.31 ms per token,   433.18 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1585.27 ms /  1212 tokens (    1.31 ms per token,   764.54 tokens per second)\n",
            "llama_print_timings:        eval time =   13451.84 ms /   255 runs   (   52.75 ms per token,    18.96 tokens per second)\n",
            "llama_print_timings:       total time =   16021.47 ms /  1467 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     594.35 ms /   256 runs   (    2.32 ms per token,   430.73 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1758.54 ms /  1403 tokens (    1.25 ms per token,   797.82 tokens per second)\n",
            "llama_print_timings:        eval time =   13433.19 ms /   255 runs   (   52.68 ms per token,    18.98 tokens per second)\n",
            "llama_print_timings:       total time =   16182.91 ms /  1658 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     581.08 ms /   256 runs   (    2.27 ms per token,   440.56 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1585.72 ms /  1244 tokens (    1.27 ms per token,   784.50 tokens per second)\n",
            "llama_print_timings:        eval time =   13561.33 ms /   255 runs   (   53.18 ms per token,    18.80 tokens per second)\n",
            "llama_print_timings:       total time =   16120.34 ms /  1499 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     606.69 ms /   256 runs   (    2.37 ms per token,   421.96 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1827.50 ms /  1444 tokens (    1.27 ms per token,   790.15 tokens per second)\n",
            "llama_print_timings:        eval time =   13519.33 ms /   255 runs   (   53.02 ms per token,    18.86 tokens per second)\n",
            "llama_print_timings:       total time =   16350.77 ms /  1699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     618.73 ms /   256 runs   (    2.42 ms per token,   413.75 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1704.37 ms /  1284 tokens (    1.33 ms per token,   753.36 tokens per second)\n",
            "llama_print_timings:        eval time =   13430.73 ms /   255 runs   (   52.67 ms per token,    18.99 tokens per second)\n",
            "llama_print_timings:       total time =   16166.72 ms /  1539 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     576.57 ms /   256 runs   (    2.25 ms per token,   444.00 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1821.65 ms /  1444 tokens (    1.26 ms per token,   792.69 tokens per second)\n",
            "llama_print_timings:        eval time =   13630.62 ms /   255 runs   (   53.45 ms per token,    18.71 tokens per second)\n",
            "llama_print_timings:       total time =   16392.23 ms /  1699 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     610.60 ms /   256 runs   (    2.39 ms per token,   419.26 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1746.30 ms /  1388 tokens (    1.26 ms per token,   794.82 tokens per second)\n",
            "llama_print_timings:        eval time =   13656.14 ms /   255 runs   (   53.55 ms per token,    18.67 tokens per second)\n",
            "llama_print_timings:       total time =   16367.55 ms /  1643 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     620.48 ms /   256 runs   (    2.42 ms per token,   412.58 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1694.82 ms /  1320 tokens (    1.28 ms per token,   778.84 tokens per second)\n",
            "llama_print_timings:        eval time =   13556.74 ms /   255 runs   (   53.16 ms per token,    18.81 tokens per second)\n",
            "llama_print_timings:       total time =   16226.08 ms /  1575 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     646.97 ms /   256 runs   (    2.53 ms per token,   395.69 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1543.05 ms /  1181 tokens (    1.31 ms per token,   765.37 tokens per second)\n",
            "llama_print_timings:        eval time =   13493.28 ms /   255 runs   (   52.91 ms per token,    18.90 tokens per second)\n",
            "llama_print_timings:       total time =   16061.79 ms /  1436 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     613.66 ms /   256 runs   (    2.40 ms per token,   417.17 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1689.04 ms /  1315 tokens (    1.28 ms per token,   778.55 tokens per second)\n",
            "llama_print_timings:        eval time =   13510.01 ms /   255 runs   (   52.98 ms per token,    18.87 tokens per second)\n",
            "llama_print_timings:       total time =   16173.00 ms /  1570 tokens\n",
            "Llama.generate: prefix-match hit\n",
            "\n",
            "llama_print_timings:        load time =     614.04 ms\n",
            "llama_print_timings:      sample time =     589.68 ms /   256 runs   (    2.30 ms per token,   434.13 tokens per second)\n",
            "llama_print_timings: prompt eval time =    1594.39 ms /  1225 tokens (    1.30 ms per token,   768.32 tokens per second)\n",
            "llama_print_timings:        eval time =   13546.47 ms /   255 runs   (   53.12 ms per token,    18.82 tokens per second)\n",
            "llama_print_timings:       total time =   16073.35 ms /  1480 tokens\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get faithfulness score\n",
        "\n",
        "faithfulness_score = sum(result.passing for result in eval_results['faithfulness']) / len(eval_results['faithfulness'])\n",
        "\n",
        "faithfulness_score"
      ],
      "metadata": {
        "id": "XX-fTceBHB_A",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b70c899b-de64-4b28-f677-e0e77d254335"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7321428571428571"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Let's get relevancy score\n",
        "\n",
        "relevancy_score = sum(result.passing for result in eval_results['relevancy']) / len(eval_results['relevancy'])\n",
        "\n",
        "relevancy_score\n"
      ],
      "metadata": {
        "id": "D73B_xEAHB8L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07deee71-5f4c-4a54-9681-732ce9662540"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8392857142857143"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    }
  ]
}